[{"path":"https://cwolock.github.io/survML/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU GENERAL PUBLIC LICENSE","title":"GNU GENERAL PUBLIC LICENSE","text":"Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU GENERAL PUBLIC LICENSE","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: assert copyright software, offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU GENERAL PUBLIC LICENSE","text":"License refers version 3 GNU General Public License. Copyright also means copyright-like laws apply kinds works, semiconductor masks. Program refers copyrightable work licensed License. licensee addressed . Licensees recipients may individuals organizations. modify work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called modified version earlier work work based earlier work. covered work means either unmodified Program work based Program. propagate work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. convey work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays Appropriate Legal Notices extent includes convenient prominently visible feature displays appropriate copyright notice, tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU GENERAL PUBLIC LICENSE","text":"source code work means preferred form work making modifications . Object code means non-source form work. Standard Interface means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. System Libraries executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. Major Component, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . Corresponding Source work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU GENERAL PUBLIC LICENSE","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU GENERAL PUBLIC LICENSE","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 keep intact notices. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called aggregate compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. User Product either consumer product, means tangible personal property normally used personal, family, household purposes, anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, normally used refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. Installation Information User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU GENERAL PUBLIC LICENSE","text":"Additional permissions terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered restrictions within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU GENERAL PUBLIC LICENSE","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated provisionally, unless copyright holder explicitly finally terminates license, permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU GENERAL PUBLIC LICENSE","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. entity transaction transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU GENERAL PUBLIC LICENSE","text":"contributor copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s contributor version. contributor’s essential patent claims patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, control includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, patent license express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). grant patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either cause Corresponding Source available, arrange deprive benefit patent license particular work, arrange, manner consistent requirements License, extend patent license downstream recipients. Knowingly relying means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license discriminatory include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license connection copies covered work conveyed (copies made copies), primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU GENERAL PUBLIC LICENSE","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License later version applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU GENERAL PUBLIC LICENSE","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU GENERAL PUBLIC LICENSE","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU GENERAL PUBLIC LICENSE","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"END OF TERMS AND CONDITIONS","what":"How to Apply These Terms to Your New Programs","title":"GNU GENERAL PUBLIC LICENSE","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least copyright line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use box. also get employer (work programmer) school, , sign copyright disclaimer program, necessary. information , apply follow GNU GPL, see http://www.gnu.org/licenses/. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read http://www.gnu.org/philosophy/--lgpl.html.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details."},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Conditional survival function estimation","text":"survML package implements two methods estimating conditional survival function using --shelf machine learning. first, called global survival stacking performed using stackG() function, involves decomposing conditional cumulative hazard function regression functions depending observed data. second, called local survival stacking discrete-time hazard estimation, involves discretizing time estimating probability event interest within discrete time period. procedure implemented stackL() function. functions can used left-truncated, right-censored data (commonly seen prospective studies) right-truncated data (commonly seen retrospective studies). details method, well examples, follow.","code":""},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"global-survival-stacking","dir":"Articles","previous_headings":"","what":"Global survival stacking","title":"Conditional survival function estimation","text":"basic survival analysis setting right-censored data (simplicity, don’t discuss truncation ), ideal data individual consist covariate vector XX, event time TT, censoring time CC. observed data consist XX, observed follow-time Y:=min(T,C)Y:=\\text{min}(T,C), event indicator Δ:=(T≤C)\\Delta := (T \\leq C). Global survival stacking requires three components: (1) conditional probability Δ=1\\Delta = 1 given XX, (2) CDF YY given XX among among censored subjects, (3) CDF YY given XX among uncensored subjects. three can estimated using standard binary regression classification methods. Estimating (1) standard binary regression problem. use pooled binary regression estimate (2) (3). essence, time tt user-specified grid, CDF binary regression using outcome (Y≤t)(Y \\leq t). data sets tt combined single, pooled data set, including tt covariate. Currently, survML allows Super Learner used binary regression, learners added future versions. stackG() function performs global survival stacking. important user-specified arguments described : bin_size: size time grid used estimating (2) (3). cases, finer grid performs better coarser grid, increased computational cost. recommend using fine grid computational resources time allow. simulations, grid 40 time points performed similarly grid every observed follow-time. Bin size given quantile terms; bin_size = 0.025 use times corresponding quantiles {0,0.025,0.05,…,0.975,1}\\{0, 0.025, 0.05, \\dots, 0.975, 1\\}. NULL, grid every observed time used. time_basis: time variable tt included pooled data set. default continuous (.e., include time -). also possible include dummy variable time grid (.e., treat time factor variable) using option dummy. learner: Currently, supported option SuperLearner. SL_control: named list arguments passed directly SuperLearner() function. SL.library gives library algorithms included Super Learner binary regression. argument vector algorithm names, can either default algorithms included SuperLearner package, user-specified algorithms. See SuperLearner package documentation information. time_grid_approx: grid times used approximate cumulative hazard product integral. argument defaults grid every observed follow-time, can substantial computational cost large samples. Using coarser grid (e.g., ~100 time points) decrease runtime usually little impact performance.","code":""},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"example","dir":"Articles","previous_headings":"Global survival stacking","what":"Example","title":"Conditional survival function estimation","text":"’s small example applying stackG() simulated data. can plot fitted versus true conditional survival various times one particular individual data set:  stackG() function simultaneously produces estimates conditional censoring distribution. may useful, example, producing inverse probability censoring (IPCW) weights.","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # note that this a very small library, just for demonstration SL.library <- c(\"SL.mean\", \"SL.glm\", \"SL.gam\")  fit <- stackG(time = time,               event = event,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               time_grid_approx = sort(unique(time)),               surv_form = \"exp\",               SL_control = list(SL.library = SL.library,                                 V = 5)) plot_dat <- data.frame(fitted = fit$S_T_preds[1,],                         true = S0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Global survival stacking example (event time distribution)\")  p plot_dat <- data.frame(fitted = fit$S_C_preds[1,],                         true = G0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Global survival stacking example (censoring time distribution)\")  p"},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"local-survival-stacking","dir":"Articles","previous_headings":"","what":"Local survival stacking","title":"Conditional survival function estimation","text":"discrete time--event variables, hazard function single time conditional probability whose estimation can framed binary regression problem: among experienced event time tt, proportion experience outcome time? Local survival stacking assumes discrete survival process based estimating conditional event probability time user-specified grid. binary regressions estimated jointly “stacking” data sets corresponding times grid. idea dates back least work Polley van der Laan (2011) also recently described Craig et al. (2021).","code":""},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"example-1","dir":"Articles","previous_headings":"Local survival stacking","what":"Example","title":"Conditional survival function estimation","text":"","code":"fit <- stackL(time = time,               event = event,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               SL_control = list(SL.library = SL.library,                                 V = 5)) plot_dat <- data.frame(fitted = fit$S_T_preds[1,],                         true = S0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Local survival stacking example\")  p"},{"path":"https://cwolock.github.io/survML/articles/v1_conditional_survival.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Conditional survival function estimation","text":"details global survival stacking, please see following paper: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). Local survival stacking described : Eric C. Polley Mark J. van der Laan. “Super Learning Right-Censored Data.” Targeted Learning (2011). Erin Craig, Chenyang Zhong, Robert Tibshirani. “Survival stacking: casting survival analysis classification problem.” arXiv:2107.13480 (2021).","code":""},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Variable importance in survival analysis: overview","text":"survML package includes functions can used estimate model-free, algorithm-agnostic variable importance outcome interest subject right censoring. Specifically, functionality aimed estimating intrinsic variable importance, population-level predictiveness potential feature group features. Suppose access vector XX features, wish use make prediction involving TT, time--event outcome. use CC denote right censoring variable. observed data given (X,Y,Δ)(X, Y, \\Delta), Δ:=(T≤C)\\Delta := (T \\leq C) Y:=min(T,C)Y := \\text{min}(T, C). index set ss, use XsX_s denote elements XX index ss X−sX_{-s} complement. given prediction task (say, estimating probability TT smaller landmark time τ\\tau) prediction function ff, require measure predictiveness. let V(f,P0)V(f, P_0) denote predictiveness ff sampling distribution P0P_0. define f0,sf_{0,s} oracle prediction function excluding features index ss; best possible prediction function, according VV, uses X−sX_{-s}. intrinsic variable importance, consider nested index sets r⊂sr \\subset s define importance Xs\\rX_{s \\setminus r} relative XsX_s V(f0,r,P0)−V(f0,s,P0)V(f_{0,r}, P_0) - V(f_{0,s}, P_0); difference maximum achievable predictiveness rr excluded compared ss excluded. refer parameter variable importance measure (VIM). Colloquially, refer X−rX_{-r} X−sX_{-s} ‘large’ ‘small’ feature groups, respectively. Variable importance assessed comparing predictiveness model using large feature group model using small feature group. Due right censoring, VIM estimation procedure requires estimates conditional survival functions TT CC given XX, define pointwise S0(t∣x):=P0(T>t∣X=x)S_0(t \\mid x) := P_0(T > t \\mid X = x) G0(t∣x):=P0(C>t∣X=x)G_0(t \\mid x) := P_0(C > t \\mid X = x), respectively. functions must estimated interval (0,τ](0, \\tau] may obtained conditional survival estimation algorithm. may simple Cox proportional hazards model (Cox, 1972) parametric survival regression model, complex stacked regression procedure survival Super Learner (Westling et al., 2023) global survival stacking (Wolock et al., 2024). also require estimates oracle prediction functions f0,rf_{0,r} f0,sf_{0,s}, refer ‘large’ ‘small’ oracle prediction functions, respectively, whose exact form depends chosen predictiveness measure. several commonly used measures, oracle prediction functions can written terms S0(⋅∣x)S_0(\\cdot \\mid x). form oracle prediction function measures included survML given Appendix.","code":""},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"example-predicting-recurrence-free-survival-time-in-cancer-patients","dir":"Articles","previous_headings":"","what":"Example: Predicting recurrence-free survival time in cancer patients","title":"Variable importance in survival analysis: overview","text":"example, consider estimating variable importance predicting recurrence-free survival using gbsg dataset survival package. Kaplan-Meier estimate survival curve dataset shown .  consider time-varying AUC importance using landmark times 1000 2000 days. first step prepare data. use dummy coding factors. means assess importance tumor grade, example, three levels, create two dummy variables called tumgrad2 tumgrad3 consider single feature group. also consider feature groups defined tumor-level features patient-level features.","code":"data(cancer) km_fit <- survfit(Surv(rfstime, status) ~ 1, data = gbsg) plot(km_fit, xlab = \"Time (days)\", ylab = \"Recurrence-free survival probability\") ### variables of interest # rfstime - recurrence-free survival # status - censoring indicator # hormon - hormonal therapy treatment indicator # age - in years # meno - 1 = premenopause, 2 = post # size - tumor size in mm # grade - factor 1,2,3 # nodes - number of positive nodes # pgr - progesterone receptor in fmol # er - estrogen receptor in fmol  # create dummy variables and clean data gbsg$tumgrad2 <- ifelse(gbsg$grade == 2, 1, 0) gbsg$tumgrad3 <- ifelse(gbsg$grade == 3, 1, 0) gbsg <- gbsg %>% na.omit() %>% select(-c(pid, grade))  time <- gbsg$rfstime event <- gbsg$status X <- gbsg %>% select(-c(rfstime, status)) # remove outcome   # find column indices of features/feature groups X_names <- names(X) age_index <- paste0(which(X_names == \"age\")) meno_index <- paste0(which(X_names == \"meno\")) size_index <- paste0(which(X_names == \"size\")) nodes_index <- paste0(which(X_names == \"nodes\")) pgr_index <- paste0(which(X_names == \"pgr\")) er_index <- paste0(which(X_names == \"er\")) hormon_index <- paste0(which(X_names == \"hormon\")) grade_index <- paste0(which(X_names %in% c(\"tumgrad2\", \"tumgrad3\")), collapse = \",\") tum_index <- paste0(which(X_names %in% c(\"size\", \"nodes\", \"pgr\", \"er\", \"tumgrad2\", \"tumgrad3\")),                     collapse = \",\") person_index <- paste0(which(X_names %in% c(\"age\", \"meno\", \"hormon\")), collapse = \",\")  feature_group_names <- c(\"age\", \"meno.\", \"size\", \"nodes\",                          \"prog.\", \"estro.\", \"hormone\",                           \"grade\") feature_groups <- c(age_index, meno_index, size_index, nodes_index,                     pgr_index, er_index, hormon_index, grade_index)"},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"estimating-variable-importance-relative-to-all-features","dir":"Articles","previous_headings":"Example: Predicting recurrence-free survival time in cancer patients","what":"Estimating variable importance relative to all features","title":"Variable importance in survival analysis: overview","text":"First, consider importance feature groups relative full feature vector. , features interest subtracted full feature vector, importance measured resulting loss predictiveness. begin estimating importance age relative full feature vector using vim() function. case, compare AUC achieved features included AUC features except age included; therefore, large_feature_vector consists features, small_feature_vector consists features except age. three options estimating nuisance functions (conditional survival functions two oracle prediction functions). Briefly, include Use survML’s built-algorithms, based using stackG() estimate conditional survival functions SuperLearner() estimate oracle prediction functions. Provide function estimate nuisance. Provide pre-computed estimates nuisance. ordered least flexible; vignette, focus (1), although also use (3) , repeat calls vim() using already-computed nuisance estimates. using built-nuisance estimation algorithms, control parameters can set using conditional_surv_generator_control, large_oracle_generator_control, small_oracle_generator_control arguments. reduce runtime example, use small Super Learner library large bin_size estimate conditional survival nuisance functions (see stackG() function documentation), well two oracle prediction functions (see SuperLearner package documentation). also use two-fold cross-fitting (.e, set cf_fold_num = 2) two-fold cross-validation nuisance estimation (.e., set V = 2 nuisance estimator). Finally, use relatively coarse grid 40 timepoints, evenly spaced quantile scale observed event times, approx_times argument, determines grid integrals approximated estimation procedure. actual analyses, generally good idea use larger library learners, cross-fitting cross-validation folds, finer grid approx_times, smaller bin_size. Note also set sample_split = TRUE. order obtain valid inference null hypothesis zero importance, sample splitting required. option set FALSE, p-value returned, caution used interpreting resulting confidence interval. want examine features, simply repeat call vim(), substituting correct large_feature_vector small_feature_vector. However, computationally inefficient, many nuisance functions needed estimate VIMs identical required estimate importance age. case, conditional survival functions TT CC, well large oracle prediction function, feature group interest; changes iterate different feature groups small oracle prediction function. Note addition results data frame (output$results), vim() function also returned several objects: folds contains cross-fitting sample-splitting folds generated call vim() approx_times grid times used estimate quantities needed variable importance conditional_surv_preds contains estimated conditional survival functions TT CC large_oracle_preds contains estimated large oracle prediction function (using features) small_oracle_preds contains estimated small oracle prediction function (using features except, case, age) examine importance features relative full feature vector, can recycle conditional_surv_preds large_oracle_preds (requires us use folds approx_times well). example using pre-computed nuisance estimates vim() function. can look results feature groups.  can also look importance tumor-level features person-level features relative full feature vector.","code":"# landmark times for AUC landmark_times <- c(1000, 2000)  output <- vim(type = \"AUC\",               time = time,               event = event,               X = X,               landmark_times = landmark_times,               large_feature_vector = 1:ncol(X),               small_feature_vector = (1:ncol(X))[-as.numeric(age_index)],               conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2,                                                         bin_size = 0.5),               large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                     V = 2),               small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                     V = 2),               approx_times = sort(unique(stats::quantile(time[event == 1 & time <= max(landmark_times)],                                                          probs = seq(0, 1, by = 0.025)))),               cf_fold_num = 2,               sample_split = TRUE,               scale_est = TRUE) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred output$result$indx <- rep(age_index, nrow(output$result)) output$result$indx_name <- rep(\"age\", nrow(output$result)) output$result #>   landmark_time est   var_est cil        ciu cil_1sided         p #> 1          1000   0 0.5064895   0 0.06755926          0 0.5799834 #> 2          2000   0 3.3089520   0 0.08363344          0 0.8661705 #>   large_predictiveness small_predictiveness vim large_feature_vector #> 1            0.7049526            0.7127091 AUC    1,2,3,4,5,6,7,8,9 #> 2            0.6523270            0.7612004 AUC    1,2,3,4,5,6,7,8,9 #>   small_feature_vector indx indx_name #> 1      2,3,4,5,6,7,8,9    1       age #> 2      2,3,4,5,6,7,8,9    1       age # save the objects that we will reuse saved_conditional_surv_preds <- output$conditional_surv_preds saved_large_oracle_preds <- output$large_oracle_preds saved_folds <- output$folds saved_approx_times <- output$approx_times  pooled_output <- output$result # save the results for age  # iterate over other feature groups for (i in 2:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      output <- vim(type = \"AUC\",                 time = time,                 event = event,                 X = X,                 landmark_times = landmark_times,                 approx_times = saved_approx_times,                 large_feature_vector = 1:ncol(X),                 small_feature_vector = (1:ncol(X))[-indx],                 conditional_surv_preds = saved_conditional_surv_preds,                 large_oracle_preds = saved_large_oracle_preds,                 cf_folds = saved_folds$cf_folds,                 ss_folds = saved_folds$ss_folds,                 small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                       V = 2),                 sample_split = TRUE,                 scale_est = TRUE)      output$result$indx <- rep(indx_char, nrow(output$result))   output$result$indx_name <- rep(indx_name, nrow(output$result))   pooled_output <- rbind(pooled_output, output$result) }  plot_results <- function(results, plot_title){   # plot results   p_auc <- results %>%     mutate(landmark_time = factor(landmark_time,                                   levels = c(1000, 2000),                                   labels = c(\"1000 days\", \"2000 days\"))) %>%     arrange(landmark_time, est) %>%     mutate(Order = row_number()) %>%     {ggplot(., aes(x = est, y = Order)) +         geom_errorbarh(aes(xmin = cil, xmax = ciu)) +         geom_point() +         theme_bw() +         xlab(\"Estimated importance\") +         ylab(\"Feature group\") +         xlim(c(0,0.5)) +         scale_y_continuous(           breaks = .$Order,           labels = .$indx_name,         ) +          facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +          ggtitle(plot_title)+         theme(strip.background = element_blank(),               strip.placement = \"outside\")     }   return(p_auc) }  p_auc <- plot_results(pooled_output, \"AUC variable importance relative to full feature vector\") p_auc # consider joint importance of all tumor-level and person-level features feature_group_names2 <- c(\"tumor\", \"person\") feature_groups2 <- c(tum_index, person_index) # repeat the analysis for feature groups for (i in 1:length(feature_group_names2)){   indx_char <- feature_groups2[i]   indx_name <- feature_group_names2[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      output <- vim(type = \"AUC\",                 time = time,                 event = event,                 X = X,                 landmark_times = landmark_times,                 approx_times = saved_approx_times,                 large_feature_vector = 1:ncol(X),                 small_feature_vector = (1:ncol(X))[-indx],                 conditional_surv_preds = saved_conditional_surv_preds,                 large_oracle_preds = saved_large_oracle_preds,                 small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                       V = 2),                 cf_folds = saved_folds$cf_folds,                 ss_folds = saved_folds$ss_folds,                 sample_split = TRUE,                 scale_est = TRUE)      output$result$indx <- rep(indx_char, nrow(output$result))   output$result$indx_name <- rep(indx_name, nrow(output$result))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output$result)   } else{     pooled_output <- output$result   } }  p_auc <- plot_results(pooled_output, \"AUC variable importance relative to full feature vector (groups)\") p_auc"},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"estimating-variable-importance-relative-to-base-model","dir":"Articles","previous_headings":"Example: Predicting recurrence-free survival time in cancer patients","what":"Estimating variable importance relative to base model","title":"Variable importance in survival analysis: overview","text":"Next, consider importance tumor-level features relative baseline set person-level features. , feature interest added baseline set features, importance measured resulting gain predictiveness. (Referring VIM “relative base model” abuse terminology — accurate describe VIM feature interest relative baseline features feature interest. framework, importance feature always considered relative set features feature interest removed.) analysis, large oracle predictions use baseline features plus feature interest, small oracle predictions use baseline features. means can recycle small oracle predictions feature groups. (NB: vim() takes care hood, worth noting large small oracle prediction functions analysis estimated regressing conditional survival function estimates given features relevant reduced feature set. previous analysis, step necessary account censoring may informed covariates, even included current set predictors.)","code":"# For importance relative to baseline features, the 'small' model uses only person-level (baseline) features # The 'large' model uses baseline + feature of interest size_index <- paste0(c(size_index, person_index), collapse = \",\") nodes_index <- paste0(c(nodes_index, person_index), collapse = \",\") pgr_index <- paste0(c(pgr_index, person_index), collapse = \",\") er_index <- paste0(c(er_index, person_index), collapse = \",\") grade_index <- paste0(c(grade_index, person_index), collapse = \",\")  feature_group_names <- c(\"size\", \"nodes\", \"prog.\", \"estro.\", \"grade\") feature_groups <- c(size_index, nodes_index,                     pgr_index, er_index, grade_index)  person_index_numeric <- as.numeric(strsplit(person_index, split = \",\")[[1]])  for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      if (i == 1){     output <- vim(type = \"AUC\",                   time = time,                   event = event,                   X = X,                   landmark_times = landmark_times,                   approx_times = saved_approx_times,                   large_feature_vector = indx,                   small_feature_vector =  person_index_numeric,                   conditional_surv_preds = saved_conditional_surv_preds,                   large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   cf_folds = saved_folds$cf_folds,                   ss_folds = saved_folds$ss_folds,                   sample_split = TRUE,                   scale_est = TRUE)     saved_small_oracle_preds <- output$small_oracle_preds   } else{     output <- vim(type = \"AUC\",                   time = time,                   event = event,                   X = X,                   landmark_times = landmark_times,                   approx_times = saved_approx_times,                   large_feature_vector = indx,                   small_feature_vector =  person_index_numeric,                   conditional_surv_preds = saved_conditional_surv_preds,                   small_oracle_preds = saved_small_oracle_preds,                   large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   cf_folds = saved_folds$cf_folds,                   ss_folds = saved_folds$ss_folds,                   sample_split = TRUE,                   scale_est = TRUE)   }      output$result$indx <- rep(indx_char, nrow(output$result))   output$result$indx_name <- rep(indx_name, nrow(output$result))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output$result)   } else{     pooled_output <- output$result   } }  p_auc <- plot_results(pooled_output, \"AUC variable importance relative to person-level features\") p_auc"},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"adjustment-variables","dir":"Articles","previous_headings":"Example: Predicting recurrence-free survival time in cancer patients","what":"Adjustment variables","title":"Variable importance in survival analysis: overview","text":"may covariates thought influence TT CC scientific interest terms variable importance. (may think covariates analogous confounders causal inference setting.) important adjust variables analyses. gbsg analysis, example, may wish adjust person-level covariates age, menopausal status, hormone treatment therapy, assess variable importance using predictiveness tumor-level covariates. use rr denote index set adjustment variables, use ss denote index set variables interest. importance XsX_s relative X−rX_{-r} (.e., full covariate vector excluding adjustment variables) given V(f0,r,P0)−V(f0,(r∪s),P0)V(f_{0, r}, P_0) - V(f_{0, (r \\cup s)}, P_0). , analyze VIM tumor-level covariate relative tumor-level covariates, adjusting person-level covariates. time, large feature vector consists features except person-level features, remains examine feature groups. Note first iteration loop, save large oracle prediction function estimates recycle feature group VIM estimates.","code":"size_index <- paste0(c(size_index, person_index), collapse = \",\") nodes_index <- paste0(c(nodes_index, person_index), collapse = \",\") pgr_index <- paste0(c(pgr_index, person_index), collapse = \",\") er_index <- paste0(c(er_index, person_index), collapse = \",\") grade_index <- paste0(c(grade_index, person_index), collapse = \",\")  feature_group_names <- c(\"size\", \"nodes\", \"prog.\", \"estro.\", \"grade\") feature_groups <- c(size_index, nodes_index,                     pgr_index, er_index, grade_index)  for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      if (i == 1){     output <- vim(type = \"AUC\",                   time = time,                   event = event,                   X = X,                   landmark_times = landmark_times,                   approx_times = saved_approx_times,                   large_feature_vector = (1:ncol(X))[-person_index_numeric],                   small_feature_vector =  (1:ncol(X))[-indx],                   conditional_surv_preds = saved_conditional_surv_preds,                   large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   cf_folds = saved_folds$cf_folds,                   ss_folds = saved_folds$ss_folds,                   sample_split = TRUE,                   scale_est = TRUE)     saved_large_oracle_preds <- output$large_oracle_preds   } else{     output <- vim(type = \"AUC\",                   time = time,                   event = event,                   X = X,                   landmark_times = landmark_times,                   approx_times = saved_approx_times,                   large_feature_vector = (1:ncol(X))[-person_index_numeric],                   small_feature_vector =  (1:ncol(X))[-indx],                   conditional_surv_preds = saved_conditional_surv_preds,                   large_oracle_preds = saved_large_oracle_preds,                   small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2),                   cf_folds = saved_folds$cf_folds,                   ss_folds = saved_folds$ss_folds,                   sample_split = TRUE,                   scale_est = TRUE)   }      output$result$indx <- rep(indx_char, nrow(output$result))   output$result$indx_name <- rep(indx_name, nrow(output$result))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output$result)   } else{     pooled_output <- output$result   } }  p_auc <- plot_results(pooled_output, \"Adjusted AUC variable importance relative to all tumor-level features\") p_auc"},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"writing-a-custom-generator-function","dir":"Articles","previous_headings":"","what":"Writing a custom generator function","title":"Variable importance in survival analysis: overview","text":"far, ’ve used two three options nuisance estimation: using built-generators, providing pre-computed estimates. third option write custom generator function. order maintain double-robustness, strongly recommend using built-generator functions estimate large small oracle prediction functions. , describe write custom conditional_surv_generator estimate S0S_0 G0G_0. function must satisfy following criteria: Input: arguments time (follow-times YY training), event (event indicators Δ\\Delta training), X (covariates training), X_holdout (covariate values generate conditional survival function estimates), newtimes (times estimate conditional survival function) Ouput: named list elements S_hat (estimated event conditional survival function X_holdout, rows corresponding rows X_holdout columns newtimes), S_hat_train (estimated event conditional survival function X, rows corresponding rows X columns newtimes), G_hat (analogous S_hat censoring), G_hat_train (analogous S_hat_train censoring). example, suppose , instead using stackG estimate conditional survival functions, wish use simple Cox proportional hazards model. first write generator function: Next, estimate importance age relative available features:","code":"generate_nuisance_predictions_coxph <- function(time,                                                 event,                                                 X,                                                 X_holdout,                                                 newtimes){      S_fit <- survival::coxph(     survival::Surv(time, event) ~ .,     data = as.data.frame(cbind(time=time,                                event=event,                                X))   )   S_hat <- t(summary(survival::survfit(S_fit,                                        newdata=X_holdout,                                        se.fit = FALSE,                                        conf.int = FALSE),                      times=newtimes)$surv)   S_hat <- S_hat[,-ncol(S_hat)]   if(ncol(S_hat) < length(newtimes)) {     S_hat <- cbind(S_hat, matrix(S_hat[,ncol(S_hat)],                                  nrow=nrow(S_hat),                                  ncol=length(newtimes) - ncol(S_hat)))        }   S_hat_train <- t(summary(survival::survfit(S_fit,                                              newdata=X,                                              se.fit = FALSE,                                              conf.int = FALSE),                            times=newtimes)$surv)   S_hat_train <- S_hat_train[,-ncol(S_hat_train)]   if(ncol(S_hat_train) < length(newtimes)) {     S_hat_train <- cbind(S_hat_train, matrix(S_hat_train[,ncol(S_hat_train)],                                              nrow=nrow(S_hat_train),                                              ncol=length(newtimes) - ncol(S_hat_train)))        }   cens_event <- 1 - event   G_fit <- survival::coxph(     survival::Surv(time, event) ~ .,     data = as.data.frame(cbind(time=time,                                event=cens_event,                                X))   )   G_hat <- t(summary(survival::survfit(G_fit,                                        newdata=X_holdout,                                        se.fit = FALSE,                                        conf.int = FALSE),                      times=newtimes)$surv)   G_hat <- G_hat[,-ncol(G_hat)]   if(ncol(G_hat) < length(newtimes)) {     G_hat <- cbind(G_hat, matrix(G_hat[,ncol(G_hat)],                                  nrow=nrow(G_hat),                                  ncol=length(newtimes) - ncol(G_hat)))        }   G_hat_train <- t(summary(survival::survfit(G_fit,                                              newdata=X,                                              se.fit = FALSE,                                              conf.int = FALSE),                            times=newtimes)$surv)   G_hat_train <- G_hat_train[,-ncol(G_hat_train)]   if(ncol(G_hat_train) < length(newtimes)) {     G_hat_train <- cbind(G_hat_train, matrix(G_hat_train[,ncol(G_hat_train)],                                              nrow=nrow(G_hat_train),                                              ncol=length(newtimes) - ncol(G_hat_train)))        }      return(list(S_hat = S_hat,               G_hat = G_hat,               S_hat_train = S_hat_train,               G_hat_train = G_hat_train)) } output <- vim(type = \"AUC\",               time = time,               event = event,               X = X,               landmark_times = landmark_times,               large_feature_vector = 1:ncol(X),               small_feature_vector = (1:ncol(X))[-as.numeric(age_index)],               conditional_surv_generator = generate_nuisance_predictions_coxph,               large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                     V = 2),               small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                     V = 2),               approx_times = sort(unique(stats::quantile(time[event == 1 & time <= max(landmark_times)],                                                          probs = seq(0, 1, by = 0.025)))),               cf_fold_num = 2,               sample_split = TRUE,               scale_est = TRUE) output$result$indx <- rep(age_index, nrow(output$result)) output$result$indx_name <- rep(\"age\", nrow(output$result)) output$result #>   landmark_time         est   var_est cil        ciu cil_1sided         p #> 1          1000 0.008546815 0.7294774   0 0.09893402          0 0.4264851 #> 2          2000 0.005337593 0.8129113   0 0.10075390          0 0.4563472 #>   large_predictiveness small_predictiveness vim large_feature_vector #> 1            0.7080532            0.6995064 AUC    1,2,3,4,5,6,7,8,9 #> 2            0.7012409            0.6959033 AUC    1,2,3,4,5,6,7,8,9 #>   small_feature_vector indx indx_name #> 1      2,3,4,5,6,7,8,9    1       age #> 2      2,3,4,5,6,7,8,9    1       age"},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Variable importance in survival analysis: overview","text":"example predictiveness measures, along corresponding oracle prediction functions, given . V(f,P0)=P0{f(X1)>f(X2)∣T1≤τ,T2>τ}V(f, P_0) = P_0\\{f(X_1) > f(X_2) \\mid T_1 \\leq \\tau, T_2 > \\tau\\} f0(x)=1−S0(τ∣x)f_0(x) = 1 - S_0(\\tau \\mid x) V(f,P0)=EP0[{f(X)−(T≤τ)}2]V(f, P_0) = E_{P_0}[\\{f(X) - (T \\leq \\tau)\\}^2] f0(x)=1−S0(τ∣x)f_0(x) = 1 - S_0(\\tau \\mid x) V(f,P0)=EP0[{f(X)−(T∧τ)}2]V(f, P_0) = E_{P_0}[\\{f(X) - (T \\wedge \\tau)\\}^2] f0(x)=∫0τS0(t∣x)dtf_0(x) = \\int_0^\\tau S_0(t \\mid x)dt V(f,P0)=EP0[{f(X)−(T≤τ)}2]varP0[(T≤τ)]V(f, P_0) = \\frac{E_{P_0}[\\{f(X) - (T \\leq \\tau)\\}^2]}{var_{P_0}[(T \\leq \\tau)]} f0(x)=1−S0(τ∣x)f_0(x) = 1 - S_0(\\tau \\mid x) V(f,P0)=P0{f(X)=(T≤τ)}V(f, P_0) = P_0\\{f(X) = (T \\leq \\tau)\\} f0(x)={S0(τ∣x)≤0.5}f_0(x) = \\{S_0(\\tau \\mid x) \\leq 0.5\\} V(f,P0)=P0{f(X1)>f(X2)∣T1≤T2}V(f, P_0) = P_0\\{f(X_1) > f(X_2) \\mid T_1 \\leq T_2\\} C-index, , knowledge, closed form oracle prediction function; see preprint details proposed procedure direct numerical optimization.","code":""},{"path":"https://cwolock.github.io/survML/articles/v2_variable_importance.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Variable importance in survival analysis: overview","text":"survival variable importance methodology described Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Assessing variable importance survival analysis using machine learning.” Biometrika (2025). references: David R. Cox. “Regression Models Life-Tables.” Journal Royal Statistical Society: Series B (Methodological) (1972). Ted Westling, Alex Luedtke, Peter B. Gilbert Marco Carone. “Inference treatment-specific survival curves using machine learning.” Journal American Statistical Association (2023). Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). Mark J. van der Laan, Eric C. Polley Alan E. Hubbard. “Super learner.” Statistical Applications Genetics Molecular Biology (2007). Daniel Rubin Mark J. van der Laan. “doubly robust censoring unbiased transformation.” International Journal Biostatistics (2007).","code":""},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Variable importance in survival analysis: multi-seed estimation","text":"discussed variable importance overview vignette, order obtain valid inference VIM null hypothesis zero importance, employ sample-splitting. also use cross-fitting order allow use flexible machine learning algorithms nuisance parameter estimation. (general overview variable importance, read overview vignette first. use notation .) recall importance covariate set Xs\\rX_{s \\setminus r} relative larger covariate set XsX_s V(f0,r,P0)−V(f0,s,P0)V(f_{0,r}, P_0) - V(f_{0,s}, P_0); difference maximum achievable predictiveness rr excluded compared ss excluded full covariate set XX. Sample-splitting entails estimating V(f0,r,P0)V(f_{0,r}, P_0) V(f0,s,P0)V(f_{0,s}, P_0) using separate portions data. serves distinct purpose cross-fitting, involves dividing data KK folds, estimating nuisance parameters using K−1K-1 folds, estimating predictiveness using remaining holdout fold, repeating process KK folds, averaging results. recommend using cross-fitting conjunction sample-splitting, illustrated figure .  cross-fitting change large-sample variance VIM estimator, sample-splitting lead estimator larger variance. Furthermore, sample-splitting cross-fitting introduce additional randomness inferential procedure due random allocation data units folds.","code":""},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"muli-seed-vim-estimation","dir":"Articles","previous_headings":"","what":"Muli-seed VIM estimation","title":"Variable importance in survival analysis: multi-seed estimation","text":"iteration VIM procedure depends seed selected user. seed determines pseudo-random process data divided folds, along stochastic components VIM estimation procedure (e.g., cross-validation selection algorithm tuning parameters). order mitigate randomness, generally recommend performing VIM procedure multiple times using different seeds, aggregating results. functionality carried multiseed_vim() function. Suppose use JJ different seeds perform VIM analyses. denote VIM point estimate produced jjth seed ψn,j\\psi_{n,j}, corresponding estimated (scaled) variance σn,j2\\sigma^2_{n,j}. Aggregating point estimates inferential results across JJ iterations require different approaches.","code":""},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"point-estimates","dir":"Articles","previous_headings":"Muli-seed VIM estimation","what":"Point estimates","title":"Variable importance in survival analysis: multi-seed estimation","text":"point estimates {ψn,1,ψn,2,…,ψn,J}\\{\\psi_{n,1}, \\psi_{n,2}, \\ldots, \\psi_{n,J}\\}. point estimates consistent true VIM ψ0\\psi_{0}, many aggregation strategies produce valid results. recommend simple averaging, constructing overall VIM estimate ψ‾n:=1J∑j=1Jψn,j\\bar{\\psi}_{n} := \\frac{1}{J}\\sum_{j = 1}^{J}\\psi_{n,j}.","code":""},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"inference","dir":"Articles","previous_headings":"Muli-seed VIM estimation","what":"Inference","title":"Variable importance in survival analysis: multi-seed estimation","text":"Combining inferential results — confidence intervals pp-values — across multiple seeds complicated. JJ iterations procedure produces valid hypothesis test null hypothesis Hc:ψ0=cH_{c}: \\psi_0 = c value cc (often, interested testing H0H_0 — , zero importance — can test point null). Thus, aggregating pp-values various seeds manner controls Type error aggregated hypothesis test allows us obtain single pp-value corresponding hypothesis test HcH_c. large literature combining multiple pp-values testing hypothesis; see Vovk Wang (2020) -depth analysis potential aggregation methods. Example aggregation methods include Bonferroni (multiply smallest pp-value number seeds) arithmetic mean (take arithmetic mean pp-values multiply two). survML, use Wald test statistic (σn,j2)−1/2(ψn,j−c)(\\sigma^2_{n,j})^{-1/2}(\\psi_{n,j} - c) test HcH_c. denote resulting pp-value pn,j,cp_{n,j,c}. apply aggregation function g()g() produce combined pp-value pn,c*=g(pn,c,1,pn,c,2,…,pn,c,J)p^*_{n,c} = g(p_{n,c,1}, p_{n,c,2}, \\ldots, p_{n,c,J}). 1−α1-\\alpha confidence interval ψ0\\psi_0 consists values cc pn,c*>αp^*_{n,c} > \\alpha, .e., reject null HcH_c. pp-values correspond one-sided test, resulting interval one-sided (.e., form (Ln,∞)(L_n, \\infty) lower bound LnL_n); pp-values correspond two-sided test, resulting interval two-sided. multiseed_vim() function produces types intervals, along aggregated pp-value corresponding one-sided test H0H_0 (zero importance).","code":""},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"example-predicting-recurrence-free-survival-time-in-cancer-patients","dir":"Articles","previous_headings":"","what":"Example: Predicting recurrence-free survival time in cancer patients","title":"Variable importance in survival analysis: multi-seed estimation","text":"variable importance overview vignette, consider importance various features predicting recurrence-free survival time using gbsg dataset survival package. illustration, look importance tumor-level features (size, nodes, estrogen receptor, progesterone receptor, grade) relative full feature vector. three arguments unique multiseed_vim() compared standard vim() function. first n_seed, determines number iterations perform. second ci_grid, determines values cc hypothesis tests performed. argument correspond range values feasible confidence interval span. example, AUC predictiveness, importance feature outside (0,1)(0,1), reasonable bounds ci_grid. third argument agg_method, determines pp-value aggregation method. Vovk Wang (2020) found compound Bonferroni-geometric mean method \"compound_bg\" work well simulations; default multiseed_vim(). , compare results single call vim() versus multiseed approach 3 seeds.","code":"data(cancer)  ### variables of interest # rfstime - recurrence-free survival # status - censoring indicator # hormon - hormonal therapy treatment indicator # age - in years # meno - 1 = premenopause, 2 = post # size - tumor size in mm # grade - factor 1,2,3 # nodes - number of positive nodes # pgr - progesterone receptor in fmol # er - estrogen receptor in fmol  # create dummy variables and clean data gbsg$tumgrad2 <- ifelse(gbsg$grade == 2, 1, 0) gbsg$tumgrad3 <- ifelse(gbsg$grade == 3, 1, 0) gbsg <- gbsg %>% na.omit() %>% select(-c(pid, grade))  time <- gbsg$rfstime event <- gbsg$status X <- gbsg %>% select(-c(rfstime, status)) # remove outcome   # find column indices of features/feature groups X_names <- names(X) tum_index <- which(X_names %in% c(\"size\", \"nodes\", \"pgr\", \"er\", \"tumgrad2\", \"tumgrad3\"))  landmark_times <- c(1000, 2000)  output_single <- vim(type = \"AUC\",                      time = time,                      event = event,                      X = X,                      landmark_times = landmark_times,                      large_feature_vector = 1:ncol(X),                      small_feature_vector = (1:ncol(X))[-as.numeric(tum_index)],                      conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                                V = 2,                                                                bin_size = 0.5),                      large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                            V = 2),                      small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                            V = 2),                      approx_times = sort(unique(stats::quantile(time[event == 1 & time <= max(landmark_times)],                                                                 probs = seq(0, 1, by = 0.025)))),                      cf_fold_num = 2,                      sample_split = TRUE,                      scale_est = TRUE) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred  output_single$result #>   landmark_time        est   var_est       cil       ciu cil_1sided #> 1          1000 0.18408503 0.5787338 0.1035768 0.2645933  0.1165204 #> 2          2000 0.05050178 2.6346037 0.0000000 0.2222763  0.0000000 #>              p large_predictiveness small_predictiveness vim #> 1 3.705528e-06            0.7049526            0.5208675 AUC #> 2 2.822298e-01            0.6523270            0.6018252 AUC #>   large_feature_vector small_feature_vector #> 1    1,2,3,4,5,6,7,8,9                1,2,7 #> 2    1,2,3,4,5,6,7,8,9                1,2,7  output_multiseed <- multiseed_vim(n_seed = 3,                                   ci_grid = seq(0, 1, by = 0.01),                                   type = \"AUC\",                                   agg_method = \"compound_bg\",                                   time = time,                                   event = event,                                   X = X,                                   landmark_times = landmark_times,                                   large_feature_vector = 1:ncol(X),                                   small_feature_vector = (1:ncol(X))[-as.numeric(tum_index)],                                   conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                                             V = 2,                                                                             bin_size = 0.5),                                   large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                                         V = 2),                                   small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                                         V = 2),                                   approx_times = sort(unique(stats::quantile(time[event == 1 & time <= max(landmark_times)],                                                                              probs = seq(0, 1, by = 0.025)))),                                   cf_fold_num = 2,                                   sample_split = TRUE,                                   scale_est = TRUE) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred output_multiseed$agg_result #>   landmark_time       est   var_est  cil  ciu cil_1sided            p #> 1          1000 0.1718534 0.5610887 0.09 0.27       0.10 7.046226e-06 #> 2          2000 0.1746481 2.9069883 0.00 0.32       0.02 2.665718e-02 #>   large_predictiveness small_predictiveness vim large_feature_vector #> 1            0.7079477            0.5360943 AUC    1,2,3,4,5,6,7,8,9 #> 2            0.7174815            0.5428334 AUC    1,2,3,4,5,6,7,8,9 #>   small_feature_vector #> 1                1,2,7 #> 2                1,2,7"},{"path":"https://cwolock.github.io/survML/articles/v3_sample_splitting.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Variable importance in survival analysis: multi-seed estimation","text":"survival variable importance methodology described Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Assessing variable importance survival analysis using machine learning.” Biometrika (2025). Methods aggregating pp-values discussed Vladimir Vovk Ruodu Wang. “Combining p-values via averaging.” Biometrika (2020).","code":""},{"path":"https://cwolock.github.io/survML/articles/v4_cindex_boosting.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Variable importance in survival analysis: maximizing C-index","text":"notion intrinsic variable importance uses idea oracle prediction function. given predictiveness measure, oracle prediction function function features achieves optimal predictiveness. optimality defined respect class possible prediction functions. Generally, consider class less unrestricted; result, oracle prediction function can take complex form rather restricted , say, additive function features. predictiveness measures, time-varying AUC, fairly straightforward characterize oracle prediction function (see Appendix overview vignette examples). notable exception concordance index C-index, popular predictiveness measure survival analysis. given prediction function ff, C-index measures probability , randomly selected pair individuals, individual first experiences event interest higher value ff. Using XX denote feature vector TT outcome, C-index VV prediction function ff distribution P0P_0 can written V(f,P0)=P0{f(X1)>f(X2)∣T1<T2}.\\begin{align*} V(f, P_0) = P_0\\left\\{f(X_1) > f(X_2) \\mid T_1 < T_2 \\right\\}. \\end{align*} general, seems optimizer f0f_0 C-index available closed form. reason, take direct optimization approach.","code":""},{"path":"https://cwolock.github.io/survML/articles/v4_cindex_boosting.html","id":"boosting-the-c-index","dir":"Articles","previous_headings":"","what":"Boosting the C-index","title":"Variable importance in survival analysis: maximizing C-index","text":"first note C-index can written V(f,P0)=P0{f(X1)>f(X2)∣T1<T2}=P0{f(X1)>f(X2),T1<T2}P0{T1<T2}.\\begin{align*} V(f, P_0) = P_0\\left\\{f(X_1) > f(X_2) \\mid T_1 < T_2 \\right\\} = \\frac{P_0\\left\\{f(X_1) > f(X_2), T_1 < T_2 \\right\\}}{P_0\\left\\{T_1 < T_2 \\right\\}}.  \\end{align*} denominator involve ff, focus maximizing numerator, can write EP0[{f(X1)>f(X2)}(T1<T2)]E_{P_0}\\left[\\{f(X_1) > f(X_2)\\}(T_1 < T_2)\\right]. Maximization objective function respect ff difficult indicator function {f(X1)>f(X2)}\\{f(X_1) > f(X_2)\\}. Chen et al. (2013) Mayr Schmid (2014) proposed optimizing smooth approximation C-index, aforementioned indicator function replaced sigmoid function hσ(s)={1+exp(s/σ)}h_\\sigma(s) = \\{1 + \\exp(s/\\sigma)\\}, σ\\sigma tuning parameter determining smoothness approximation. P0P_0 unknown, TT subject right censoring, must optimize estimate smoothed C-index. survML, implement optimization doubly-robust estimate smoothed C-index using gradient boosting. details, see Wolock et al. (2025). rely mboost gradient boosting R package, allows gradient boosting various types base learners ff, including trees, additive models, linear models. boosting tuning parameters mstop (number boosting iterations) nu (learning rate), along smoothness parameter σ\\sigma selected via cross-validation. experience, found boosting procedure tends relatively insensitive choice σ\\sigma. gradient boosting algorithms, generally advisable set small learning rate nu use cross-validation select number iterations mstop; however, computational cost large mstop can quite large. Another computational consideration calculation smoothed C-index estimate gradient, involve double sum. allow user subsample observations boosting procedure, using subsample_n parameter, can greatly decrease computation time without substantial loss performance.","code":""},{"path":"https://cwolock.github.io/survML/articles/v4_cindex_boosting.html","id":"example-predicting-recurrence-free-survival-time-in-cancer-patients","dir":"Articles","previous_headings":"","what":"Example: Predicting recurrence-free survival time in cancer patients","title":"Variable importance in survival analysis: maximizing C-index","text":"variable importance overview vignette, consider importance various features predicting recurrence-free survival time using gbsg dataset survival package. illustration, look importance tumor-level features (size, nodes, estrogen receptor, progesterone receptor, grade) relative full feature vector. use vim() function. Compared estimating time-varying AUC importance, overview vignette, several key differences keep mind. First, C-index predictiveness measure involve landmark_time, argument longer relevant. However, order ensure C-index identified right censoring, must choose restriction_time. essence, value τ\\tau events occur τ\\tau considered computing C-index. data-driven way select restriction_time, simulations shown values restriction_time ~10% individuals still -risk experiencing event perform reasonably well. choose 2000 days restriction_time example. Second, procedure estimating nuisance parameters slightly different C-index, since large small oracle prediction functions longer estimated using SuperLearner(), rather gradient boosting procedure described . control parameters relevant gradient boosting instead: V: Number folds cross-validation selection tuning parameters. tuning: Whether tune boosting parameters, simply use (single) user-provided value parameter without tuning. subsample_n: Size subsample computation boosting objective function gradient. Subsampling proportions 1/4, 1/3, 1/2 perform well simulations, somewhat larger bias variance smaller subsample proportions smaller overall sample sizes. boosting_params: Named list parameters actual gradient boosting procedure, including mstop, nu, sigma, learner (base learner mboost use; options glm, gam, tree). Note provide multiple values mstop set tuning = TRUE — trigger cross-validation procedure (case, V = 2 folds) select estimated optimal mstop among two provided values.","code":"data(cancer)  ### variables of interest # rfstime - recurrence-free survival # status - censoring indicator # hormon - hormonal therapy treatment indicator # age - in years # meno - 1 = premenopause, 2 = post # size - tumor size in mm # grade - factor 1,2,3 # nodes - number of positive nodes # pgr - progesterone receptor in fmol # er - estrogen receptor in fmol  # create dummy variables and clean data gbsg$tumgrad2 <- ifelse(gbsg$grade == 2, 1, 0) gbsg$tumgrad3 <- ifelse(gbsg$grade == 3, 1, 0) gbsg <- gbsg %>% na.omit() %>% select(-c(pid, grade))  time <- gbsg$rfstime event <- gbsg$status X <- gbsg %>% select(-c(rfstime, status)) # remove outcome   # find column indices of features/feature groups X_names <- names(X) tum_index <- which(X_names %in% c(\"size\", \"nodes\", \"pgr\", \"er\", \"tumgrad2\", \"tumgrad3\")) restriction_time <- 2000  output <- vim(type = \"C-index\",               time = time,               event = event,               X = X,               restriction_time = 2000,               large_feature_vector = 1:ncol(X),               small_feature_vector = (1:ncol(X))[-as.numeric(tum_index)],               conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                                         V = 2,                                                         bin_size = 0.5),               large_oracle_generator_control = list(V = 2,                                                     tuning = TRUE,                                                     subsample_n = 300,                                                     boosting_params = list(mstop = c(100, 200),                                                                            nu = 0.1,                                                                            sigma = 0.1,                                                                            learner = \"glm\")),               small_oracle_generator_control = list(V = 2,                                                     tuning = TRUE,                                                     subsample_n = 300,                                                     boosting_params = list(mstop = c(100, 200),                                                                            nu = 0.1,                                                                            sigma = 0.1,                                                                            learner = \"glm\")),               approx_times = sort(unique(stats::quantile(time[event == 1 & time <= 2000],                                                          probs = seq(0, 1, by = 0.025)))),               cf_fold_num = 2,               sample_split = FALSE,               scale_est = TRUE) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred output$result #>   restriction_time        est   var_est        cil       ciu cil_1sided  p #> 1             2000 0.09958167 0.5763206 0.04277254 0.1563908 0.05190595 NA #>   large_predictiveness small_predictiveness     vim large_feature_vector #> 1            0.6343642            0.5347826 C-index    1,2,3,4,5,6,7,8,9 #>   small_feature_vector #> 1                1,2,7"},{"path":"https://cwolock.github.io/survML/articles/v4_cindex_boosting.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Variable importance in survival analysis: maximizing C-index","text":"survival variable importance methodology described Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Assessing variable importance survival analysis using machine learning.” Biometrika (2025). references: Yifei Chen, Zhenyu Jia, Dan Mercola Xiaohui Xie. “Gradient Boosting Algorithm Survival Analysis via Direct Optimization Concordance Index.” Computational Mathematical Methods Medicine (2013). Andreas Mayr Matthias Schmid. “Boosting Concordance Index Survival Data – Unified Framework Derive Evaluate Biomarker Combinations.” PLoS One (2014).","code":""},{"path":"https://cwolock.github.io/survML/articles/v5_current_status.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Covariate-adjusted survival curves with current status data","text":"Current status data arise analysis time--event variables study participant’s event status observed single monitoring time. current status sampling scheme represents particular form interval censoring: participant’s event time known lie either event time support’s lower bound monitoring time, monitoring time even time support’s upper bound. Traditional nonparametric methods estimating event time distribution current status sampling require independence event time monitoring time, may unrealistic. function currstatCIR() implements nonparametric estimation approach requires conditional independence event time monitoring times given measured baseline covariates. method implemented currstatCIR() called extended causal isotonic regression, extended CIR short, due connection causal isotonic regression procedure proposed Westling et al. (2020). Specifically, estimation survival function using current status data subject covariate-informed monitoring analogous estimation monotone causal dose-response curve covariate-induced confounding. , describe method provide example analysis using simulated data.","code":""},{"path":"https://cwolock.github.io/survML/articles/v5_current_status.html","id":"current-status-data-structure","dir":"Articles","previous_headings":"","what":"Current status data structure","title":"Covariate-adjusted survival curves with current status data","text":"Suppose interested estimating survival function time--event outcome TT. However, directly observe TT; rather, study participant, observe monitoring time YY indicator whether TT smaller YY, denoted Δ:=(T≤Y)\\Delta := (T \\leq Y). addition, observe baseline covariate vector XX. data structure commonly referred current status data, represents extreme form interval censoring. extended CIR method implemented survML originally devised analyze symptom survey data long COVID study conducted University Washington. Study participants tested positive SARS-CoV-2 infection sent email survey 28 days positive test, queried presence persistent COVID-19 symptoms time survey response. participants choose respond survey, substantial variation response time. example, event time TT represents duration COVID-19 symptoms infection, monitoring time YY represents number days since positive test participant chose complete survey. Baseline covariate information included demographics (sex, age, etc.), preexisting comorbidities, characteristics participant’s acute infection (symptoms, viral load, etc.) One key complication long COVID study survey nonresponse. time data collection ended, fewer half surveyed individuals responded email survey. use c0c_0 denote time — measured since positive test — follow-ends study participant. many cases, c0c_0 must determined investigator. consider participant responded survey time c0c_0 nonrespondent. long COVID data publicly available, vignette, analyze simple simulated dataset, generated . Note event time TT monitoring time YY depend covariates X1X_1 X2X_2. maximum follow-time c0c_0 set 1.65, YY Δ\\Delta set NA individuals responded time.","code":"# Simulate some current status data n <- 250 x <- cbind(2*rbinom(n, size = 1, prob = 0.5)-1,            2*rbinom(n, size = 1, prob = 0.5)-1) t <- rweibull(n,               shape = 0.75,               scale = exp(0.8*x[,1] - 0.4*x[,2])) y <- rweibull(n,               shape = 0.75,               scale = exp(0.8*x[,1] - 0.4*x[,2]))  # Round y to nearest quantile of y, just so there aren't so many unique values # This will speed computation in this example analysis quants <- quantile(y, probs = seq(0, 1, by = 0.025), type = 1) for (i in 1:length(y)){   y[i] <- quants[which.min(abs(y[i] - quants))] } delta <- as.numeric(t <= y)  dat <- data.frame(y = y, delta = delta, x1 = x[,1], x2 = x[,2])  dat$delta[dat$y > 1.65] <- NA dat$y[dat$y > 1.65] <- NA"},{"path":"https://cwolock.github.io/survML/articles/v5_current_status.html","id":"extended-cir-method","dir":"Articles","previous_headings":"","what":"Extended CIR method","title":"Covariate-adjusted survival curves with current status data","text":"Details extended method can found corresponding manuscript (Wolock et al., 2025). essence, procedure consists steps outlined . steps involve two nuisance functions must estimated: (1) μ(y,x):=E(Δ∣Y=y,X=x)\\mu(y,x) := E(\\Delta \\mid Y = y, X = x), conditional mean Δ\\Delta given YY XX; (2) g(y,x):=π(y∣x)/E{π(y∣X)}g(y,x) := \\pi(y \\mid x)/E\\{\\pi(y \\mid X)\\}, standardization conditional density YY given XX. familiar causal inference continuous exposures, two nuisance functions can thought analogous outcome regression (standardized) propensity score. Extended CIR procedure: Construct estimates μn\\mu_n gng_n μ\\mu gg, respectively. Construct pseudo-outcomes Γn(Δ1,Y1,X1),…,Γn(Δn,Yn,Xn)\\Gamma_n(\\Delta_1, Y_1, X_1), \\ldots, \\Gamma_n(\\Delta_n, Y_n, X_n), defined pointwise Γn(δ,y,x)=δ−μn(y,x)gn(y,x)+1n∑j=1nμn(y,Xj)\\Gamma_n(\\delta, y, x) = \\frac{\\delta - \\mu_n(y,x)}{g_n(y,x)} + \\frac{1}{n}\\sum_{j=1}^{n}\\mu_n(y, X_j). Regress pseudo-outcomes Y1,…,YnY_1, \\ldots, Y_n using isotonic regression. isotonic regression step requires investigator choose region perform regression. denote region [t0,t1][t_0,t_1]. endpoints region chosen t0t_0 larger lower bound support YY, t1t_1 smaller c0c_0. Isotonic regression known perform poorly near boundaries support YY, choosing t0t_0 t1t_1 lie slightly inside boundaries (example, 2.5th 97.5th percentiles distribution YY) may wise. details provided manuscript. currstatCIR() function uses SuperLearner() estimate μ\\mu haldensify() estimate gg. Control parameters functions can passed using arguments SL_control HAL_control. isotonic regression bounds [t0,t1][t_0,t_1] specified using argument eval_region. n_eval_pts argument specifies number time points, evenly spaced quantile scale YY, estimate survival function. , analyze simulated data using currstatCIR(). control parameters nuisance function estimate chosen speed computation purpose illustration; real data analyses generally advisable use larger number cross-validation folds larger SuperLearner() library. can plot estimated survival function, along pointwise 95% confidence band, compare true survival function, shown red.","code":"eval_region <- c(0.02, 1.5) res <- currstatCIR(time = dat$y,                    event = dat$delta,                    X = dat[,3:4],                    SL_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                      V = 2),                    HAL_control = list(n_bins = c(5),                                       grid_type = c(\"equal_mass\", \"equal_range\"),                                       V = 2),                    eval_region = eval_region,                    n_eval_pts = 100)$primary_results #> Warning in (function (X, Y, formula = NULL, X_unpenalized = NULL, max_degree = ifelse(ncol(X) >= : Some fit_control arguments are neither default nor glmnet/cv.glmnet arguments: n_folds;  #> They will be removed from fit_control #> 20% of observations outside training support...predictions trimmed. # use Monte Carlo to approximate the true survival function n_test <- 5e5 x_test <- cbind(2*rbinom(n_test, size = 1, prob = 0.5)-1,                 2*rbinom(n_test, size = 1, prob = 0.5)-1) t_test <- rweibull(n_test,                    shape = 0.75,                    scale = exp(0.8*x_test[,1] - 0.4*x_test[,2]))  S0 <- function(x){   return(mean(t_test > x)) }  other_data <- data.frame(t = seq(min(res$t), max(res$t), length.out = 1000)) other_data$y <- apply(as.matrix(other_data$t), MARGIN = 1, FUN = S0)  # plot the results p1 <- ggplot(data = res, aes(x = t)) +   geom_step(aes(y = S_hat_est)) +   geom_step(aes(y = S_hat_cil), linetype = \"dashed\") +   geom_step(aes(y = S_hat_ciu), linetype = \"dashed\") +   geom_smooth(data = other_data, aes(x = t, y = y), color = \"red\") +   theme_bw() +   ylab(\"Estimated survival probability\") +   xlab(\"Time\") +    scale_y_continuous(limits = c(0, 1)) +   ggtitle(\"Covariate-adjusted survival curve\") p1 #> `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://cwolock.github.io/survML/articles/v5_current_status.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Covariate-adjusted survival curves with current status data","text":"details extended CIR, please see following paper: Charles J. Wolock, Susan Jacob, Julia C. Bennett, Anna Elias-Warren, Jessica O’Hanlon, Avi Kenny, Nicholas P. Jewell, Andrea Rotnitzky, Stephen R. Cole, Ana . Weil, Helen Y. Chu Marco Carone. “Investigating symptom duration using current status data: case study post-acute COVID-19 syndrome.” Epidemiology (2025). references: Ted Westling, Peter Gilbert Marco Carone. “Causal isotonic regression.” Journal Royal Statistical Society Series B: Statistical Methodology (2020). Mark J. van der Laan, Eric C. Polley Alan E. Hubbard. “Super learner.” Statistical Applications Genetics Molecular Biology (2007). Nima S. Hejazi, Mark J. van der Laan David Benkeser. “haldensify: Highly adaptive lasso conditional density estimation R.” Journal Open Source Software (2022).","code":""},{"path":"https://cwolock.github.io/survML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Charles Wolock. Author, maintainer, copyright holder. Avi Kenny. Contributor.","code":""},{"path":"https://cwolock.github.io/survML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wolock C (2025). survML: Tools Flexible Survival Analysis Using Machine Learning. R package version 1.2.0.9000, https://github.com/cwolock/survML.","code":"@Manual{,   title = {survML: Tools for Flexible Survival Analysis Using Machine Learning},   author = {Charles Wolock},   year = {2025},   note = {R package version 1.2.0.9000},   url = {https://github.com/cwolock/survML}, }"},{"path":"https://cwolock.github.io/survML/index.html","id":"survml-tools-for-flexible-survival-analysis-using-machine-learning","dir":"","previous_headings":"","what":"Tools for Flexible Survival Analysis Using Machine Learning","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"survML package contains variety functions analyzing survival data using machine learning. include: Global local survival stacking: Use --shelf machine learning tools estimate conditional survival functions. Algorithm-agnostic variable importance: Use debiased machine learning estimate make inference variable importance prediction time--event outcomes. (1.2.0+) Current-status isotonic regression: Use isotonic regression estimate covariate-adjusted survival function time--event outcome current status sampling. (1.2.0+) See package vignettes function reference details.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"installing-survml","dir":"","previous_headings":"","what":"Installing survML","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"can install stable version survML CRAN using Alternatively, development version survML available GitHub. can install using devtools package follows:","code":"install.packages(\"survML\") ## install.packages(\"devtools\") # run only if necessary install_github(repo = \"cwolock/survML\")"},{"path":"https://cwolock.github.io/survML/index.html","id":"integration-with-cfsurvival","dir":"","previous_headings":"","what":"Integration with CFsurvival","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"CFsurvival package can used estimate covariate-adjusted counterfactual survival curve observational data. approach requires estimating conditional event censoring distributions. fork CFsurvival package, added stackG() survML option estimating nuisance parameters.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"Full documentation can found survML website https://cwolock.github.io/survML/.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"bugs-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bugs reports and feature requests","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"submit bug report request new feature, please submit new GitHub Issue.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"details methods implemented package, please see following papers: Global survival stacking: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). Survival variable importance: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Assessing variable importance survival analysis using machine learning.” Biometrika (2025). Covariate-adjusted survival curves current status data: Charles J. Wolock, Susan Jacob, Julia C. Bennett, Anna Elias-Warren, Jessica O’Hanlon, Avi Kenny, Nicholas P. Jewell, Andrea Rotnitzky, Stephen R. Cole, Ana . Weil, Helen Y. Chu Marco Carone. “Investigating symptom duration using current status data: case study post-acute COVID-19 syndrome.” Epidemiology (2025). Local survival stacking described : Eric C. Polley Mark J. van der Laan. “Super Learning Right-Censored Data” Targeted Learning (2011). Erin Craig, Chenyang Zhong, Robert Tibshirani. “Survival stacking: casting survival analysis classification problem.” arXiv:2107.13480.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"using survML package conditional survival estimation, please cite following: using variable importance functions, please cite following: using functionality current status data, please cite following:","code":"@article{wolock2024framework,         title={A framework for leveraging machine learning tools to estimate personalized survival curves},         author={Wolock, Charles J and Gilbert, Peter B and Simon, Noah and Carone, Marco},         journal={Journal of Computational and Graphical Statistics},         year={2024},         volume = {33},         number = {3},         pages = {1098--1108},         publisher={Taylor \\& Francis},         doi={10.1080/10618600.2024.2304070} } @article{wolock2025assessing,     author = {Wolock, Charles J and Gilbert, Peter B and Simon, Noah and Carone, Marco},     title = {Assessing variable importance in survival analysis using machine learning},     journal = {Biometrika},     volume = {112},     issue = {2}     pages = {asae061},     year = {2025},     doi = {10.1093/biomet/asae061},     publisher={Oxford University Press} } @article{wolock2025investigating,   title={Investigating symptom duration using current status data: a case study of post-acute COVID-19 syndrome},   author={Wolock, Charles J and Jacob, Susan and Bennett, Julia C and Elias-Warren, Anna and O'Hanlon, Jessica and Kenny, Avi and Jewell, Nicholas P and Rotnitzky, Andrea and Cole, Stephen R and Weil, Ana A and Chu, Helen Y and Carone, Marco},   journal={Epidemiology},   year={2025},   doi={10.1097/EDE.0000000000001882} }"},{"path":"https://cwolock.github.io/survML/reference/DR_pseudo_outcome_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","title":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","text":"Generate estimates conditional survival probability conditional restrcited mean survival time using doubly-robust pseudo-outcome regression SuperLearner","code":""},{"path":"https://cwolock.github.io/survML/reference/DR_pseudo_outcome_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","text":"","code":"DR_pseudo_outcome_regression(   time,   event,   X,   newX,   approx_times,   S_hat,   G_hat,   newtimes,   outcome,   SL.library,   V )"},{"path":"https://cwolock.github.io/survML/reference/DR_pseudo_outcome_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. approx_times Numeric vector length J2 giving times approximate integral appearing pseudo-outcomes S_hat n x J2 matrix conditional event time survival function estimates G_hat n x J2 matrix conditional censoring time survival function estimates newtimes Numeric vector times generate oracle prediction function estimates. outcome \"survival_probability\", times survival function estimated. outcome \"restricted_survival_time\", simply restriction time. outcome Outcome type, either \"survival_probability\" \"restricted_survival_time\" SL.library Super Learner library V Number cross-validation folds, passed SuperLearner","code":""},{"path":"https://cwolock.github.io/survML/reference/DR_pseudo_outcome_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","text":"Matrix predictions corresponding newX newtimes.","code":""},{"path":"https://cwolock.github.io/survML/reference/DR_pseudo_outcome_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly-robust pseudo-outcome regression — DR_pseudo_outcome_regression","text":"","code":"# This is a small simulation example set.seed(123) n <- 250 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2])) C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  approx_times <- c(0, sort(unique(time)))  # estimate conditional survival functions at approx_times fit <- stackG(time = time,               event = event,               X = X,               newX = X,               newtimes = approx_times,               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               surv_form = \"PI\",               learner = \"SuperLearner\",               time_grid_approx = approx_times,               SL_control = list(SL.library = SL.library,                                 V = 3))  # use DR pseudo-outcome regression to (robustly) estimate survival at t = 5 DR_preds <- DR_pseudo_outcome_regression(time = time,                                         event = event,                                         X = X,                                         newX = X,                                         newtimes = 5,                                         approx_times = approx_times,                                         S_hat = fit$S_T_preds,                                         G_hat = fit$S_C_preds,                                         outcome = \"survival_probability\",                                         SL.library = SL.library,                                         V = 3) DR_preds #>                [,1] #>   [1,]  0.717678946 #>   [2,]  0.629275538 #>   [3,]  0.150485092 #>   [4,]  0.548797775 #>   [5,]  0.533065643 #>   [6,]  0.108636652 #>   [7,]  0.668175208 #>   [8,]  1.130128400 #>   [9,]  0.975372491 #>  [10,]  0.686949376 #>  [11,]  0.240046974 #>  [12,]  0.471365958 #>  [13,]  0.684272789 #>  [14,]  0.538045226 #>  [15,]  0.940307560 #>  [16,]  0.089406689 #>  [17,]  0.434420822 #>  [18,]  1.317897945 #>  [19,]  0.379953146 #>  [20,]  0.918079525 #>  [21,]  0.853469281 #>  [22,]  0.626009552 #>  [23,]  0.842276470 #>  [24,]  0.762754921 #>  [25,]  0.958828253 #>  [26,]  1.242977085 #>  [27,]  0.567306748 #>  [28,]  0.526619255 #>  [29,]  1.096157456 #>  [30,]  0.232088984 #>  [31,]  0.677396189 #>  [32,]  0.870513268 #>  [33,]  0.328091194 #>  [34,]  0.556508132 #>  [35,]  0.347775202 #>  [36,]  0.607225483 #>  [37,]  0.419414594 #>  [38,]  0.808108686 #>  [39,]  0.873428263 #>  [40,]  0.669501189 #>  [41,]  0.977474627 #>  [42,]  0.623317652 #>  [43,]  1.130218094 #>  [44,] -0.012846040 #>  [45,]  0.468230423 #>  [46,]  1.092135157 #>  [47,]  0.675500191 #>  [48,]  0.916437227 #>  [49,]  0.582782630 #>  [50,]  0.589982660 #>  [51,]  0.499869140 #>  [52,]  0.575309617 #>  [53,]  0.803012346 #>  [54,]  0.425235485 #>  [55,]  0.851965177 #>  [56,]  0.385658930 #>  [57,]  1.206057682 #>  [58,]  0.635067895 #>  [59,]  0.758388931 #>  [60,]  0.509872979 #>  [61,]  0.466059675 #>  [62,]  0.925983697 #>  [63,]  0.880720239 #>  [64,]  0.840288101 #>  [65,]  1.078400206 #>  [66,]  0.710299564 #>  [67,]  0.447707021 #>  [68,]  0.777351746 #>  [69,]  0.544695791 #>  [70,]  0.242838564 #>  [71,]  0.922961347 #>  [72,]  1.409580986 #>  [73,]  0.522354989 #>  [74,]  0.757484821 #>  [75,]  0.975681829 #>  [76,]  0.517046782 #>  [77,]  0.643887880 #>  [78,]  0.894390948 #>  [79,]  0.743012798 #>  [80,]  0.604843053 #>  [81,]  0.789995415 #>  [82,]  0.688418927 #>  [83,]  0.890744338 #>  [84,]  0.395203516 #>  [85,]  0.850550816 #>  [86,]  0.478868610 #>  [87,]  0.274103161 #>  [88,]  0.675063035 #>  [89,]  0.878772891 #>  [90,]  0.484062933 #>  [91,]  0.525629565 #>  [92,]  0.420892193 #>  [93,]  0.727642281 #>  [94,]  0.735726518 #>  [95,]  0.203494209 #>  [96,]  0.952196038 #>  [97,]  0.206104426 #>  [98,]  0.157470068 #>  [99,]  0.854622747 #> [100,]  0.842387932 #> [101,]  0.757807550 #> [102,]  0.722783954 #> [103,]  0.633695569 #> [104,]  0.660687992 #> [105,]  0.822367290 #> [106,]  0.803589733 #> [107,]  0.777746713 #> [108,]  1.237958330 #> [109,]  0.669435755 #> [110,]  0.321702199 #> [111,]  0.945528242 #> [112,]  0.404949149 #> [113,]  1.000691085 #> [114,]  0.806409194 #> [115,]  0.652520251 #> [116,]  0.710935301 #> [117,]  0.763254236 #> [118,]  0.963021413 #> [119,]  1.018959253 #> [120,]  0.841774455 #> [121,]  0.760050390 #> [122,]  1.045127201 #> [123,]  0.922834556 #> [124,]  0.636211538 #> [125,]  0.074164478 #> [126,]  0.742161783 #> [127,]  0.504668576 #> [128,]  0.770672173 #> [129,]  0.825107481 #> [130,]  0.586754572 #> [131,]  0.404908055 #> [132,]  0.670694346 #> [133,]  0.556633275 #> [134,]  0.904618318 #> [135,]  1.117215219 #> [136,]  0.264869811 #> [137,]  1.182474547 #> [138,]  0.593493235 #> [139,]  0.280571779 #> [140,]  0.954123253 #> [141,]  0.603707505 #> [142,]  0.861714632 #> [143,]  1.212318314 #> [144,]  0.973065855 #> [145,]  0.996315979 #> [146,]  0.933633878 #> [147,]  1.182773111 #> [148,]  0.383550092 #> [149,]  0.005580680 #> [150,]  1.136008409 #> [151,]  0.580702013 #> [152,]  0.585706109 #> [153,]  0.478756034 #> [154,]  1.061427455 #> [155,]  0.823509351 #> [156,]  0.866585237 #> [157,]  0.640855558 #> [158,]  0.667351381 #> [159,]  0.530053900 #> [160,]  0.667924708 #> [161,]  0.509782808 #> [162,]  1.072347571 #> [163,]  0.904946297 #> [164,] -0.075917386 #> [165,]  0.679239961 #> [166,]  0.487849347 #> [167,]  0.621162033 #> [168,]  0.697151731 #> [169,]  0.653201456 #> [170,]  0.468916798 #> [171,]  0.625315165 #> [172,]  0.774062680 #> [173,]  0.576787164 #> [174,] -0.002005237 #> [175,]  0.766085756 #> [176,]  1.084878619 #> [177,]  0.781424221 #> [178,]  0.484569823 #> [179,]  0.450834827 #> [180,]  0.690349397 #> [181,]  1.076134547 #> [182,]  0.453450089 #> [183,]  0.885121164 #> [184,]  1.023190360 #> [185,]  0.854777771 #> [186,]  0.844311778 #> [187,]  0.494471021 #> [188,]  0.544989448 #> [189,]  0.365848700 #> [190,]  0.701303313 #> [191,]  0.510273448 #> [192,]  0.878439490 #> [193,]  0.766223158 #> [194,]  0.807310736 #> [195,]  0.918501639 #> [196,]  0.256989425 #> [197,]  0.406891064 #> [198,]  0.902568550 #> [199,]  0.731246059 #> [200,]  0.884959693 #> [201,]  0.203032543 #> [202,]  0.216405373 #> [203,]  0.638634512 #> [204,]  0.646153764 #> [205,]  0.678566121 #> [206,]  0.919004377 #> [207,]  1.002605600 #> [208,]  0.726816858 #> [209,]  0.125808238 #> [210,]  0.582129637 #> [211,]  0.759622519 #> [212,]  0.726315903 #> [213,]  0.461669350 #> [214,]  0.929661272 #> [215,]  0.833311009 #> [216,]  0.119173405 #> [217,]  0.685745297 #> [218,]  0.761195806 #> [219,]  1.122423339 #> [220,]  0.911519842 #> [221,]  0.721291604 #> [222,]  0.626135952 #> [223,]  0.494490332 #> [224,]  0.602154075 #> [225,]  0.888870075 #> [226,]  0.775546275 #> [227,]  0.980121521 #> [228,]  0.983499684 #> [229,]  0.554763871 #> [230,]  0.839489761 #> [231,]  0.044340016 #> [232,]  0.815711979 #> [233,]  0.734117447 #> [234,]  0.989203126 #> [235,]  0.721402734 #> [236,]  0.920164960 #> [237,]  0.840497669 #> [238,]  0.679398677 #> [239,]  0.480869975 #> [240,]  0.776845282 #> [241,]  1.002610721 #> [242,]  0.702081284 #> [243,]  0.167252565 #> [244,]  1.095934421 #> [245,]  0.615591830 #> [246,]  0.282376189 #> [247,]  0.818563839 #> [248,]  0.931626841 #> [249,]  0.969461925 #> [250,]  0.661606134"},{"path":"https://cwolock.github.io/survML/reference/aggregate_vim.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate multiseed VIM results — aggregate_vim","title":"Aggregate multiseed VIM results — aggregate_vim","text":"Aggregate multiseed VIM results","code":""},{"path":"https://cwolock.github.io/survML/reference/aggregate_vim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate multiseed VIM results — aggregate_vim","text":"","code":"aggregate_vim(result_list, agg_method, ci_grid, n_eff, alpha = 0.05)"},{"path":"https://cwolock.github.io/survML/reference/aggregate_vim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate multiseed VIM results — aggregate_vim","text":"result_list List result data frames return vim function. agg_method P-value aggregation method use combine results different seeds. Current options \"bonferroni\" (Bonferroni's method), \"hommel\" (Hommel's method), \"arithmetic\" (arithmetic mean), \"geometric\" (geometric mean), \"harmonic\" (harmonic mean), \"compound_bg\" (compound Bonferroni geometric mean), \"compound_ba\" (compound Bonferroni arithmetic mean). approaches discussed length Vovk Wang (2020). Defaults \"compound_bg\", shown work well many settings. ci_grid Grid VIM values construct confidence interval inverting hypothesis test. aggregation works constructing hypothesis tests (level alpha) null corresponding value ci_grid, inverting tests yield 1 - alpha confidence interval. example, \"AUC\" importance, VIM takes values (0,1), grid values 0 1 reasonable choice. n_eff effective sample size. Without sample-splitting, simply sample size. sample-splitting, sample size divided two (.e., size two halves data). alpha level compute confidence intervals hypothesis tests. Defaults 0.05.","code":""},{"path":"https://cwolock.github.io/survML/reference/aggregate_vim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate multiseed VIM results — aggregate_vim","text":"Named list following elements: agg_result Data frame giving results aggregated seeds. agg_method P-value aggregation method used. n_seed Number iterations (seeds) used perform VIM estimation procedure. vim_objects list vim return objects, corresponding different seed.","code":""},{"path":"https://cwolock.github.io/survML/reference/boost_c_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient boosting for C-index — boost_c_index","title":"Gradient boosting for C-index — boost_c_index","text":"Using doubly-robust gradient boosting generate estimates prediction function maximizes C-index","code":""},{"path":"https://cwolock.github.io/survML/reference/boost_c_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient boosting for C-index — boost_c_index","text":"","code":"boost_c_index(   time,   event,   X,   newX,   S_hat,   G_hat,   V,   approx_times,   tuning,   produce_fit = TRUE,   subsample_n,   boosting_params )"},{"path":"https://cwolock.github.io/survML/reference/boost_c_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient boosting for C-index — boost_c_index","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. S_hat n x J2 matrix conditional event time survival function estimates G_hat n x J2 matrix conditional censoring time survival function estimates V Number cross-validation folds selection tuning parameters approx_times Numeric vector length J2 giving times approximate C-index integral. Note last time approx_times taken restriction time (.e., maximum follow-) comparison pairs individuals. Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. tuning Logical, whether use cross-validation select tuning parameters produce_fit Logical, whether produce fitted prediction function using selected optimal parameters. subsample_n Number samples use boosting procedure. Using subsample full sample can greatly reduce runtime boosting_params Named list parameter values boosting procedure. Elements list include mstop (number boosting iterations), nu (learning rate), sigma (smoothness parameter sigmoid approximation, smaller meaning less smoothing), learner (base learner, can take values \"glm\", \"gam\", \"tree\")","code":""},{"path":"https://cwolock.github.io/survML/reference/boost_c_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient boosting for C-index — boost_c_index","text":"Vector predictions corresponding newX","code":""},{"path":"https://cwolock.github.io/survML/reference/boost_c_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient boosting for C-index — boost_c_index","text":"","code":"# This is a small simulation example set.seed(123) n <- 250 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2])) C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  # Note that we do not use times beyond the 90th percentile of observed follow-up times approx_times <- c(0, unique(quantile(time, probs = seq(0, 0.9, by = 0.01))))  # estimate conditional survival functions at approx_times fit <- stackG(time = time,               event = event,               X = X,               newX = X,               newtimes = approx_times,               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               surv_form = \"PI\",               learner = \"SuperLearner\",               time_grid_approx = approx_times,               SL_control = list(SL.library = SL.library,                                 V = 3))  # use boosting to estimate optimal (according to C-index) prediction function boosted_preds <- boost_c_index(time = time,                                event = event,                                X = X,                                newX = X,                                approx_times = approx_times,                                S_hat = fit$S_T_preds,                                G_hat = fit$S_C_preds,                                V = 3,                                tuning = TRUE,                                produce_fit = TRUE,                                subsample_n = 200,                                boosting_params = list(mstop = c(100, 200),                                                       nu = 0.1,                                                       sigma = 0.1,                                                       learner = \"glm\")) boosted_preds #>             1             2             3             4             5  #> -0.0686025275 -0.0322597503  0.1645717386  0.0008247817  0.0072922855  #>             6             7             8             9            10  #>  0.1817756968  0.0437814373 -0.1461282309 -0.0825078385 -0.0559695540  #>            11            12            13            14            15  #>  0.1277527111  0.0326571208  0.0371636969  0.0052451712 -0.0680925911  #>            16            17            18            19            20  #>  0.1896811642  0.0478453232 -0.2233205796  0.0702370686 -0.0589546118  #>            21            22            23            24            25  #> -0.1244261433 -0.0309170984 -0.1198247614 -0.0871333302 -0.0757064766  #>            26            27            28            29            30  #> -0.1925204988  0.0852486165  0.0099424053 -0.1321627232  0.1310242531  #>            31            32            33            34            35  #>  0.0399906780 -0.0394000504  0.0915575968  0.0896879443  0.0834654710  #>            36            37            38            39            40  #>  0.0688379632  0.0540144065 -0.0137454306 -0.0405984093 -0.0487965777  #>            41            42            43            44            45  #> -0.0833720298 -0.0298104545 -0.1461651039  0.2317174186  0.1259790461  #>            46            47            48            49            50  #> -0.1305091502 -0.0512627767 -0.0582794605  0.0788864576 -0.0161063881  #>            51            52            53            54            55  #>  0.0209394187 -0.0100742774 -0.0116503174  0.1436543313 -0.0317749018  #>            56            57            58            59            60  #>  0.1599243143 -0.1773428752  0.0573919046  0.0066944373  0.0168268254  #>            61            62            63            64            65  #>  0.0348385420 -0.0622040291 -0.0435961517 -0.1190073398 -0.1248626905  #>            66            67            68            69            70  #>  0.0264640498  0.0423833464 -0.0011012053  0.0945440156  0.2186379862  #>            71            72            73            74            75  #> -0.0609615364 -0.2610116188  0.1037283539 -0.0849667839 -0.0826350075  #>            76            77            78            79            80  #>  0.1059105661 -0.0382669069 -0.1412491036  0.0130155890 -0.0222155182  #>            81            82            83            84            85  #> -0.0062990372  0.0354592134 -0.0477170746  0.0639676182 -0.0311934555  #>            86            87            88            89            90  #>  0.0295727689  0.1137521602  0.0409498411 -0.0427955941  0.1194702770  #>            91            92            93            94            95  #>  0.1023821707  0.0534069634  0.0193344323 -0.0760219121  0.1427796092  #>            96            97            98            99           100  #> -0.0729799630  0.2337394469  0.1617002043 -0.0328674329 -0.1198705837  #>           101           102           103           104           105  #> -0.0850994584  0.0213316979 -0.0340768321 -0.0451734586 -0.1116400670  #>           106           107           108           109           110  #> -0.0118876820 -0.0932964790 -0.1904572810 -0.0487696774  0.0941841224  #>           111           112           113           114           115  #> -0.0702388216  0.0599611731 -0.1849492534 -0.0130467668  0.0502172143  #>           116           117           118           119           120  #>  0.0262026973  0.0046943025 -0.0774302914 -0.1004264233 -0.1196183824  #>           121           122           123           124           125  #>  0.0060114085 -0.1111841069 -0.0609094126 -0.0351111506  0.1959472604  #>           126           127           128           129           130  #> -0.0786674594  0.0189663633  0.0016447772 -0.1127665637 -0.0147793158  #>           131           132           133           134           135  #>  0.1520109692  0.0427458161 -0.0023964045 -0.0534206889 -0.2328525042  #>           136           137           138           139           140  #>  0.1175480046 -0.1676478123  0.0744833117  0.2031258037 -0.1658051462  #>           141           142           143           144           145  #>  0.0702842093 -0.0357829178 -0.1799166310 -0.1735924788 -0.1831506407  #>           146           147           148           149           150  #> -0.0653490304 -0.1677705525  0.0687583584  0.2241421657 -0.1485455113  #>           151           152           153           154           155  #>  0.0797418027  0.0776846110  0.0296190493 -0.1178851664 -0.0200766677  #>           156           157           158           159           160  #> -0.0377852307  0.0550125874 -0.0479127880  0.1005633196 -0.0481484840  #>           161           162           163           164           165  #>  0.1088967967 -0.1223744430 -0.1455884238  0.3496790479 -0.0528002017  #>           166           167           168           169           170  #>  0.0258807741  0.0631086261 -0.0601637579  0.0499371699  0.0336639744  #>           171           172           173           174           175  #> -0.0306316353  0.0002509347 -0.0106816990  0.2272607475 -0.0885026416  #>           176           177           178           179           180  #> -0.1275259763 -0.0027754061  0.0272289917  0.0410975003 -0.0573673077  #>           181           182           183           184           185  #> -0.1239312745  0.1320552643 -0.0454053790 -0.1021658378 -0.0329311635  #>           186           187           188           189           190  #> -0.0286285778  0.1151914959  0.0023903907  0.0760354280 -0.0618704796  #>           191           192           193           194           195  #>  0.0166621917 -0.0426585323  0.0034737741 -0.1054502942 -0.1511610458  #>           196           197           198           199           200  #>  0.2128205456  0.0591628490 -0.1446109282 -0.0741799888 -0.1373718999  #>           201           202           203           204           205  #>  0.2350023028  0.1374718097 -0.0361072393  0.0528344871 -0.0525231852  #>           206           207           208           209           210  #> -0.0593348198 -0.0937034113 -0.0723591373  0.1747164312 -0.0128779980  #>           211           212           213           214           215  #>  0.0061873072  0.0198797084  0.1286763136 -0.0637158859 -0.1161390465  #>           216           217           218           219           220  #>  0.1774440213 -0.0554745552 -0.0864923756 -0.1429606684 -0.1482908184  #>           221           222           223           224           225  #> -0.0700876969  0.0610638403  0.1151835571  0.0709228267 -0.0469465622  #>           226           227           228           229           230  #> -0.0003589733 -0.0844601719 -0.0858489400  0.0904050125 -0.1186791412  #>           231           232           233           234           235  #>  0.2082081429 -0.0168711561  0.0166724814 -0.0881936336 -0.0701333826  #>           236           237           238           239           240  #> -0.1518448395 -0.0270605915  0.0391674522  0.0287500048 -0.0929258992  #>           241           242           243           244           245  #> -0.0937055165 -0.0621903045  0.1576786048 -0.1320710332 -0.0266343571  #>           246           247           248           249           250  #>  0.2023840077 -0.0180435601 -0.1565568363 -0.0800779954  0.0464819939"},{"path":"https://cwolock.github.io/survML/reference/crossfit_oracle_preds.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate cross-fitted oracle prediction function estimates — crossfit_oracle_preds","title":"Generate cross-fitted oracle prediction function estimates — crossfit_oracle_preds","text":"Generate cross-fitted oracle prediction function estimates","code":""},{"path":"https://cwolock.github.io/survML/reference/crossfit_oracle_preds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate cross-fitted oracle prediction function estimates — crossfit_oracle_preds","text":"","code":"crossfit_oracle_preds(   time,   event,   X,   folds,   nuisance_preds,   pred_generator,   ... )"},{"path":"https://cwolock.github.io/survML/reference/crossfit_oracle_preds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate cross-fitted oracle prediction function estimates — crossfit_oracle_preds","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values folds n x 1 numeric vector folds identifiers cross-fitting nuisance_preds Named list conditional event censoring survival functions used estimate oracle prediction function. pred_generator Function used estimate oracle prediction function. ... Additional arguments passed pred_generator.","code":""},{"path":"https://cwolock.github.io/survML/reference/crossfit_oracle_preds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate cross-fitted oracle prediction function estimates — crossfit_oracle_preds","text":"Named list cross-fitted oracle prediction estimates","code":""},{"path":"https://cwolock.github.io/survML/reference/crossfit_surv_preds.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate cross-fitted conditional survival predictions — crossfit_surv_preds","title":"Generate cross-fitted conditional survival predictions — crossfit_surv_preds","text":"Generate cross-fitted conditional survival predictions","code":""},{"path":"https://cwolock.github.io/survML/reference/crossfit_surv_preds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate cross-fitted conditional survival predictions — crossfit_surv_preds","text":"","code":"crossfit_surv_preds(time, event, X, newtimes, folds, pred_generator, ...)"},{"path":"https://cwolock.github.io/survML/reference/crossfit_surv_preds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate cross-fitted conditional survival predictions — crossfit_surv_preds","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values newtimes Numeric vector times estimate conditional survival functions folds n x 1 numeric vector folds identifiers cross-fitting pred_generator Function used estimate conditional survival function. ... Additional arguments passed pred_generator.","code":""},{"path":"https://cwolock.github.io/survML/reference/crossfit_surv_preds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate cross-fitted conditional survival predictions — crossfit_surv_preds","text":"Named list cross-fitted conditional survival predictions","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a survival function under current status sampling — currstatCIR","title":"Estimate a survival function under current status sampling — currstatCIR","text":"Estimate survival function current status sampling","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a survival function under current status sampling — currstatCIR","text":"","code":"currstatCIR(   time,   event,   X,   SL_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"), V = 3),   HAL_control = list(n_bins = c(5), grid_type = c(\"equal_mass\"), V = 3),   deriv_method = \"m-spline\",   sample_split = FALSE,   m = 5,   eval_region,   n_eval_pts = 101,   alpha = 0.05,   sensitivity_analysis = FALSE,   copula_control = list(taus = c(-0.1, -0.05, 0.05, 0.1)) )"},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a survival function under current status sampling — currstatCIR","text":"time n x 1 numeric vector observed monitoring times. individuals never monitored, can set arbitrary value, including NA, long corresponding event variable NA. event n x 1 numeric vector status indicators whether event observed prior monitoring time. value must NA individuals never monitored. X n x p dataframe observed covariate values. SL_control List SuperLearner control parameters. named list; see SuperLearner documentation information. HAL_control List haldensify control parameters. named list; see haldensify documentation information. deriv_method Method computing derivative. Options \"m-spline\" (default, fit smoothing spline estimated function differentiate smooth approximation), \"linear\" (linearly interpolate estimated function use slope line), \"line\" (use slope line connecting endpoints estimated function). sample_split Logical indicating whether perform inference using sample splitting m Number sample-splitting folds, defaults 5. eval_region Region estimate survival function. n_eval_pts Number points grid evaluate survival function. points evenly spaced, quantile scale, endpoints eval_region. alpha level compute confidence intervals hypothesis tests. Defaults 0.05 sensitivity_analysis Logical, whether perform copula-based sensitivity analysis. Defaults FALSE copula_control named list control parameters copula-based sensitivity analysis. named list.","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a survival function under current status sampling — currstatCIR","text":"List data frames giving results. performing sensitivity analysis, single data frame returned; performing sensitivity analysis, separate data frame returned value copula association parameter. results data frames columns: t Time survival function estimated S_hat_est Survival function estimate S_hat_cil Lower bound confidence interval S_hat_ciu Upper bound confidence interval","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate a survival function under current status sampling — currstatCIR","text":"Wolock C.J., et al. (2025). \"Investigating symptom duration using current status data: case study post-acute COVID-19 syndrome.\"","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate a survival function under current status sampling — currstatCIR","text":"","code":"if (FALSE) # This is a small simulation example set.seed(123) n <- 300 x <- cbind(2*rbinom(n, size = 1, prob = 0.5)-1,            2*rbinom(n, size = 1, prob = 0.5)-1) t <- rweibull(n,               shape = 0.75,               scale = exp(0.4*x[,1] - 0.2*x[,2])) y <- rweibull(n,               shape = 0.75,               scale = exp(0.4*x[,1] - 0.2*x[,2]))  # round y to nearest quantile of y, just so there aren't so many unique values quants <- quantile(y, probs = seq(0, 1, by = 0.05), type = 1) for (i in 1:length(y)){   y[i] <- quants[which.min(abs(y[i] - quants))] } delta <- as.numeric(t <= y)  dat <- data.frame(y = y, delta = delta, x1 = x[,1], x2 = x[,2])  dat$delta[dat$y > 1.8] <- NA dat$y[dat$y > 1.8] <- NA eval_region <- c(0.05, 1.5) res <- survML::currstatCIR(time = dat$y,                            event = dat$delta,                            X = dat[,3:4],                            SL_control = list(SL.library = c(\"SL.mean\", \"SL.glm\"),                                              V = 3),                            HAL_control = list(n_bins = c(5),                                               grid_type = c(\"equal_mass\"),                                               V = 3),                            sensitivity_analysis = FALSE,                            eval_region = eval_region)$primary_results #> Warning: Some fit_control arguments are neither default nor glmnet/cv.glmnet arguments: n_folds;  #> They will be removed from fit_control #> 20% of observations outside training support...predictions trimmed.  xvals = res$t yvals = res$S_hat_est fn=stepfun(xvals, c(yvals[1], yvals)) plot.function(fn, from=min(xvals), to=max(xvals)) # \\dontrun{}"},{"path":"https://cwolock.github.io/survML/reference/generate_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate cross-fitting and sample-splitting folds — generate_folds","title":"Generate cross-fitting and sample-splitting folds — generate_folds","text":"Generate cross-fitting sample-splitting folds","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate cross-fitting and sample-splitting folds — generate_folds","text":"","code":"generate_folds(n, V, sample_split, cf_folds = NULL)"},{"path":"https://cwolock.github.io/survML/reference/generate_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate cross-fitting and sample-splitting folds — generate_folds","text":"n Total sample size V Number cross-fitting folds use sample_split Logical, whether sample-splitting used cf_folds Cross-fitting folds, already provided user.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate cross-fitting and sample-splitting folds — generate_folds","text":"Named list cross-fitting sample-splitting folds","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_nuisance_predictions_stackG.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate conditional survival function nuisance parameters using survival stacking — generate_nuisance_predictions_stackG","title":"Estimate conditional survival function nuisance parameters using survival stacking — generate_nuisance_predictions_stackG","text":"Estimate conditional survival function nuisance parameters using survival stacking","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_nuisance_predictions_stackG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate conditional survival function nuisance parameters using survival stacking — generate_nuisance_predictions_stackG","text":"","code":"generate_nuisance_predictions_stackG(   time,   event,   X,   X_holdout,   newtimes,   SL.library = c(\"SL.mean\", \"SL.glm\", \"SL.earth\", \"SL.gam\", \"SL.ranger\"),   V = 5,   bin_size = 0.05,   approx_times )"},{"path":"https://cwolock.github.io/survML/reference/generate_nuisance_predictions_stackG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate conditional survival function nuisance parameters using survival stacking — generate_nuisance_predictions_stackG","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values X_holdout m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. SL.library Super Learner library V Number cross-validation folds, passed SuperLearner bin_size Size time bin discretize estimation cumulative probability functions. Can number 0 1, indicating size quantile grid (e.g. 0.1 estimates cumulative probability functions grid based deciles observed times). NULL, creates grid observed times. See stackG documentation. approx_times Numeric vector times approximate product integral cumulative hazard interval. See stackG documentation.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_nuisance_predictions_stackG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate conditional survival function nuisance parameters using survival stacking — generate_nuisance_predictions_stackG","text":"list containing elements S_hat (conditional event survival function, corresponding X_holdout newtimes), S_hat_train (conditional event survival function, corresponding X newtimes), G_hat (conditional censoring survival function, corresponding X_holdout newtimes), G_hat_train (conditional censoring survival function, corresponding X newtimes)","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_DR.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate full oracle prediction function using DR pseudo-outcome regression — generate_oracle_predictions_DR","title":"Estimate full oracle prediction function using DR pseudo-outcome regression — generate_oracle_predictions_DR","text":"Estimate full oracle prediction function using DR pseudo-outcome regression","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_DR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate full oracle prediction function using DR pseudo-outcome regression — generate_oracle_predictions_DR","text":"","code":"generate_oracle_predictions_DR(   time,   event,   X,   X_holdout,   nuisance_preds,   outcome,   landmark_times,   restriction_time,   approx_times,   SL.library = c(\"SL.mean\", \"SL.glm\", \"SL.earth\", \"SL.gam\", \"SL.ranger\"),   V = 5,   indx )"},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_DR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate full oracle prediction function using DR pseudo-outcome regression — generate_oracle_predictions_DR","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values X_holdout m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. nuisance_preds Named list conditional survival function predictions elements \"S_hat\", \"S_hat_train\", \"G_hat\", \"G_hat_train\". match output conditional_surv_generator. outcome Outcome type, either \"survival_probability\" \"restricted_survival_time\" landmark_times Numeric vector length J1 giving landmark times estimate VIM (\"accuracy\", \"AUC\", \"Brier\", \"R-squared\"). restriction_time Maximum follow-time calculation \"survival_time_MSE\". Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. approx_times Numeric vector length J2 giving times approximate integral appearing pseudo-outcomes SL.library Super Learner library V Number cross-validation folds, passed SuperLearner indx Numeric index column(s) X removed, .e., used oracle prediction function.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_DR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate full oracle prediction function using DR pseudo-outcome regression — generate_oracle_predictions_DR","text":"list containing elements f0_hat f0_hat_train, estimated oracle prediction functions X_holdout X, respectively.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_SL.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate small oracle prediction function using Super Learner regression — generate_oracle_predictions_SL","title":"Estimate small oracle prediction function using Super Learner regression — generate_oracle_predictions_SL","text":"oracle prediction function conditional mean, small oracle prediction function can estimated regressing large oracle prediction function small feature vector. function performs regression using Super Learner.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_SL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate small oracle prediction function using Super Learner regression — generate_oracle_predictions_SL","text":"","code":"generate_oracle_predictions_SL(   time,   event,   X,   X_holdout,   nuisance_preds,   outcome,   landmark_times,   restriction_time,   approx_times,   SL.library = c(\"SL.mean\", \"SL.glm\", \"SL.earth\", \"SL.gam\", \"SL.ranger\"),   V = 5,   indx )"},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_SL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate small oracle prediction function using Super Learner regression — generate_oracle_predictions_SL","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values X_holdout m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. nuisance_preds Named list conditional survival function predictions elements \"S_hat\", \"S_hat_train\", \"G_hat\", \"G_hat_train\". match output conditional_surv_generator. outcome Outcome type, either \"survival_probability\" \"restricted_survival_time\" landmark_times Numeric vector length J1 giving landmark times estimate VIM (\"accuracy\", \"AUC\", \"Brier\", \"R-squared\"). restriction_time Maximum follow-time calculation \"survival_time_MSE\". Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. approx_times Numeric vector length J2 giving times approximate integral appearing pseudo-outcomes SL.library Super Learner library V Number cross-validation folds, passed SuperLearner indx Numeric index column(s) X removed, .e., used oracle prediction function.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_SL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate small oracle prediction function using Super Learner regression — generate_oracle_predictions_SL","text":"list containing elements f0_hat f0_hat_train, estimated small oracle prediction functions X_holdout X, respectively.","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_boost.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate oracle prediction function using DR gradient boosting — generate_oracle_predictions_boost","title":"Estimate oracle prediction function using DR gradient boosting — generate_oracle_predictions_boost","text":"Estimate oracle prediction function using DR gradient boosting","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_boost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate oracle prediction function using DR gradient boosting — generate_oracle_predictions_boost","text":"","code":"generate_oracle_predictions_boost(   time,   event,   X,   X_holdout,   nuisance_preds,   restriction_time,   approx_times,   V = 5,   indx,   tuning = FALSE,   subsample_n = length(time),   boosting_params = list(mstop = c(100), nu = c(0.1), sigma = c(0.01), learner =     c(\"glm\")) )"},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_boost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate oracle prediction function using DR gradient boosting — generate_oracle_predictions_boost","text":"time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values X_holdout m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. nuisance_preds Named list conditional survival function predictions elements \"S_hat\", \"S_hat_train\", \"G_hat\", \"G_hat_train\". match output conditional_surv_generator. restriction_time Maximum follow-time calculation C-index. Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. approx_times Numeric vector length J2 giving times approximate C-index integral. V Number cross-validation folds selection tuning parameters indx Numeric index column(s) X removed, .e., used oracle prediction function. tuning Logical, whether use cross-validation select tuning parameters subsample_n Number samples use boosting procedure. Using subsample full sample can greatly reduce runtime boosting_params Named list parameter values boosting procedure. Elements list include mstop (number boosting iterations), nu (learning rate), sigma (smoothness parameter sigmoid approximation, smaller meaning less smoothing), learner (base learner, can take values \"glm\", \"gam\", \"tree\")","code":""},{"path":"https://cwolock.github.io/survML/reference/generate_oracle_predictions_boost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate oracle prediction function using DR gradient boosting — generate_oracle_predictions_boost","text":"list containing elements f0_hat f0_hat_train, estimated oracle prediction functions X_holdout X, respectively.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate variable importance with multiple seeds — multiseed_vim","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"Repeat VIM estimation procedure multiple times aggregate results, mitigating additional randomness introduced sample-splitting cross-fitting.","code":""},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"","code":"multiseed_vim(   n_seed,   agg_method = \"compound_bg\",   ci_grid,   type,   time,   event,   X,   landmark_times = stats::quantile(time[event == 1], probs = c(0.25, 0.5, 0.75)),   restriction_time = max(time[event == 1]),   approx_times = NULL,   large_feature_vector,   small_feature_vector,   conditional_surv_generator = NULL,   conditional_surv_generator_control = NULL,   large_oracle_generator = NULL,   large_oracle_generator_control = NULL,   small_oracle_generator = NULL,   small_oracle_generator_control = NULL,   cf_fold_num = 5,   sample_split = TRUE,   scale_est = FALSE,   alpha = 0.05,   verbose = FALSE )"},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"n_seed Number iterations (seeds) perform VIM estimation procedure. aggregated single result. agg_method P-value aggregation method use combine results different seeds. Current options \"bonferroni\" (Bonferroni's method), \"hommel\" (Hommel's method), \"arithmetic\" (arithmetic mean), \"geometric\" (geometric mean), \"harmonic\" (harmonic mean), \"compound_bg\" (compound Bonferroni geometric mean), \"compound_ba\" (compound Bonferroni arithmetic mean). approaches discussed length Vovk Wang (2020). Defaults \"compound_bg\", shown work well many settings. ci_grid Grid VIM values construct confidence interval inverting hypothesis test. aggregation works constructing hypothesis tests (level alpha) null corresponding value ci_grid, inverting tests yield 1 - alpha confidence interval. example, \"AUC\" importance, VIM takes values (0,1), grid values 0 1 reasonable choice. type Type VIM compute. Options include \"accuracy\", \"AUC\", \"Brier\", \"R-squared\" \"C-index\", \"survival_time_MSE\". time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values landmark_times Numeric vector length J1 giving landmark times estimate VIM (\"accuracy\", \"AUC\", \"Brier\", \"R-squared\"). restriction_time Maximum follow-time calculation \"C-index\" \"survival_time_MSE\". Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. approx_times Numeric vector length J2 giving times approximate integrals. Defaults grid 100 timepoints, evenly spaced quantile scale distribution observed event times. large_feature_vector Numeric vector giving indices features include 'large' prediction model. small_feature_vector Numeric vector giving indices features include 'small' prediction model. Must subset large_feature_vector. conditional_surv_generator function estimate conditional survival functions event censoring variables. Must take arguments (time, event, X) (training purposes) (X_holdout newtimes) (covariate values times generate predictions). Defaults generate_nuisance_predictions_stackG, pre-built generator function based stackG function. Alternatively, user can provide function argument, provide pre-computed estimates conditional_surv_preds lieu argument. conditional_surv_generator_control list arguments pass conditional_surv_generator. large_oracle_generator function estimate oracle prediction function using large_feature_vector. Must take arguments time, event, X, X_holdout, nuisance_preds. VIM types except \"C-index\", defaults generate_oracle_predictions_DR, pre-built generator function using doubly-robust pseudo-outcome regression. \"C-index\", defaults generate_oracle_predictions_boost, pre-built generator function using doubly-robust gradient boosting. Alternatively, user can provide function, provide pre-computed estimates large_oracle_preds lieu argument. large_oracle_generator_control list arguments pass large_oracle_generator. small_oracle_generator function estimate oracle prediction function using small_feature_vector. Must take arguments time, event, X, X_holdout, nuisance_preds. VIM types except \"C-index\", defaults generate_oracle_predictions_SL, pre-built generator function based regression large oracle predictions small feature vector. \"C-index\", defaults generate_oracle_predictions_boost, pre-built generator function using doubly-robust gradient boosting. Alternatively, user can provide function, provide pre-computed estimates small_oracle_preds lieu argument. small_oracle_generator_control list arguments pass small_oracle_generator. cf_fold_num number cross-fitting folds, providing cf_folds. Note samples-splitting, data split 2 x cf_fold_num folds (.e., cf_fold_num folds within half data). sample_split Logical indicating whether sample split. Sample-splitting required valid hypothesis testing null importance generally recommended. Defaults TRUE. scale_est Logical, whether force VIM estimate nonnegative. alpha level compute confidence intervals hypothesis tests. Defaults 0.05. verbose Whether print progress messages.","code":""},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"Named list following elements: agg_result Data frame giving results aggregated seeds. agg_method P-value aggregation method used. n_seed Number iterations (seeds) used perform VIM estimation procedure. vim_objects list vim return objects, corresponding different seed.","code":""},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"Using larger value n_seed result stable results, greater computational cost.","code":""},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"Vovk V. Wang R. (2020). \"Combining p-values via averaging.\" Wolock C.J., Gilbert P.B., Simon N., Carone, M. (2025). \"Assessing variable importance survival analysis using machine learning.\"","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/multiseed_vim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate variable importance with multiple seeds — multiseed_vim","text":"","code":"# This is a small simulation example set.seed(123) n <- 100 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # landmark times for AUC landmark_times <- c(3)  output <- multiseed_vim(n_seed = 2,               agg_method = \"compound_bg\",               ci_grid = seq(0, 1, by = 0.01),               type = \"AUC\",               time = time,               event = event,               X = X,               landmark_times = landmark_times,               large_feature_vector = 1:2,               small_feature_vector = 2,               conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               cf_fold_num = 2,               sample_split = TRUE,               scale_est = TRUE)  print(output$result) #> NULL"},{"path":"https://cwolock.github.io/survML/reference/predict.stackG.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","title":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","text":"Obtain predicted conditional survival cumulative hazard functions global survival stacking object","code":""},{"path":"https://cwolock.github.io/survML/reference/predict.stackG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","text":"","code":"# S3 method for class 'stackG' predict(   object,   newX,   newtimes,   surv_form = object$surv_form,   time_grid_approx = object$time_grid_approx,   ... )"},{"path":"https://cwolock.github.io/survML/reference/predict.stackG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","text":"object Object class stackG newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. surv_form Mapping hazard estimate survival estimate. Can either \"PI\" (product integral mapping) \"exp\" (exponentiated cumulative hazard estimate). Defaults value saved object. time_grid_approx Numeric vector times approximate product integral cumulative hazard interval. Defaults value saved object. ... arguments passed methods.","code":""},{"path":"https://cwolock.github.io/survML/reference/predict.stackG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","text":"named list following components: S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. S_C_preds m x k matrix estimated censoring time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. Lambda_T_preds m x k matrix estimated event time cumulative hazard function values m covariate vector values k times provided user newX newtimes, respectively. Lambda_C_preds m x k matrix estimated censoring time cumulative hazard function values m covariate vector values k times provided user newX newtimes, respectively. time_grid_approx approximation grid product integral cumulative hazard integral, (user-specified). surv_form Exponential product-integral form (user-specified).","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/predict.stackG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain predicted conditional survival and cumulative hazard functions from a global survival stacking object — predict.stackG","text":"","code":"# This is a small simulation example set.seed(123) n <- 250 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackG(time = time,               event = event,               entry = entry,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               time_grid_approx = sort(unique(time)),               surv_form = \"exp\",               learner = \"SuperLearner\",               SL_control = list(SL.library = SL.library,                                 V = 5))  preds <- predict(object = fit,                  newX = X,                  newtimes = seq(0, 15, 0.1))  plot(preds$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/predict.stackL.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","title":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","text":"Obtain predicted conditional survival function local survival stacking object","code":""},{"path":"https://cwolock.github.io/survML/reference/predict.stackL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","text":"","code":"# S3 method for class 'stackL' predict(object, newX, newtimes, ...)"},{"path":"https://cwolock.github.io/survML/reference/predict.stackL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","text":"object Object class stackL newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. ... arguments passed methods.","code":""},{"path":"https://cwolock.github.io/survML/reference/predict.stackL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","text":"named list following components: S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/predict.stackL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain predicted conditional survival function from a local survival stacking object — predict.stackL","text":"","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackL(time = time,                event = event,                entry = entry,                X = X,                newX = X,                newtimes = seq(0, 15, .1),                direction = \"prospective\",                bin_size = 0.1,                time_basis = \"continuous\",                SL_control = list(SL.library = SL.library,                                  V = 5))  preds <- predict(object = fit,                  newX = X,                  newtimes = seq(0, 15, 0.1))  plot(preds$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a conditional survival function using global survival stacking — stackG","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"Estimate conditional survival function using global survival stacking","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"","code":"stackG(   time,   event = rep(1, length(time)),   entry = NULL,   X,   newX = NULL,   newtimes = NULL,   direction = \"prospective\",   time_grid_fit = NULL,   bin_size = NULL,   time_basis,   time_grid_approx = sort(unique(time)),   surv_form = \"PI\",   learner = \"SuperLearner\",   SL_control = list(SL.library = c(\"SL.mean\"), V = 10, method = \"method.NNLS\", stratifyCV     = FALSE),   tau = NULL )"},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. entry Study entry variable, applicable. Defaults NULL, indicating truncation. X n x p data.frame observed covariate values train estimator. newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. direction Whether data come prospective retrospective study. determines whether data treated subject left truncation right censoring (\"prospective\") right truncation alone (\"retrospective\"). time_grid_fit Named list numeric vectors times times discretize estimation cumulative probability functions. alternative bin_size allows specially tailored time grids rather simply using quantile bin size. list consists vectors named F_Y_1_grid, F_Y_0_grid, G_W_1_grid, G_W_0_grid. denote, respectively, grids used estimate conditional CDF time variable among uncensored censored observations, grids used estimate conditional distribution entry variable among uncensored censored observations. bin_size Size time bin discretize estimation cumulative probability functions. Can number 0 1, indicating size quantile grid (e.g. 0.1 estimates cumulative probability functions grid based deciles observed times). NULL, creates grid observed times. time_basis treat time training binary classifier. Options \"continuous\" \"dummy\", meaning indicator variable included time time grid. time_grid_approx Numeric vector times approximate product integral cumulative hazard interval. Defaults times argument. surv_form Mapping hazard estimate survival estimate. Can either \"PI\" (product integral mapping) \"exp\" (exponentiated cumulative hazard estimate). learner binary regression algorithm use. Currently, SuperLearner supported, learners added. See algorithm-specific arguments. SL_control Named list parameters controlling Super Learner fitting process. parameters passed directly SuperLearner function. Parameters include SL.library (library algorithms include binary classification Super Learner), V (Number cross validation folds train Super Learner classifier, defaults 10), method (Method estimating coefficients Super Learner, defaults \"method.NNLS\"), stratifyCV (logical indicating whether stratify outcome SuperLearner's cross-validation scheme), obsWeights (observation weights, passed directly prediction algorithms SuperLearner). tau maximum time interest study, used retrospective conditional survival estimation. Rather dealing right truncation separately left truncation, simpler estimate survival function tau - time. Defaults NULL, case maximum study entry time chosen reference point.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"named list class stackG, following components: S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. S_C_preds m x k matrix estimated censoring time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. Lambda_T_preds m x k matrix estimated event time cumulative hazard function values m covariate vector values k times provided user newX newtimes, respectively. Lambda_C_preds m x k matrix estimated censoring time cumulative hazard function values m covariate vector values k times provided user newX newtimes, respectively. time_grid_approx approximation grid product integral cumulative hazard integral, (user-specified). direction Whether data come prospective retrospective study (user-specified). tau maximum time interest study, used retrospective conditional survival estimation (user-specified). surv_form Exponential product-integral form (user-specified). time_basis Whether time included regression continuous dummy (user-specified). SL_control Named list parameters controlling Super Learner fitting process (user-specified). fits named list fitted regression objects corresponding constituent regressions needed global survival stacking. Includes P_Delta (probability event given covariates), F_Y_1 (conditional cdf follow-times given covariates among uncensored), F_Y_0 (conditional cdf follow-times given covariates among censored), G_W_1 (conditional distribution entry times given covariates follow-time among uncensored), G_W_0 (conditional distribution entry times given covariates follow-time among uncensored). objects includes estimated coefficients SuperLearner fit, well time grid used create stacked dataset (applicable).","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"Wolock C.J., Gilbert P.B., Simon N., Carone, M. (2024). \"framework leveraging machine learning tools estimate personalized survival curves.\"","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"","code":"# This is a small simulation example set.seed(123) n <- 250 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackG(time = time,               event = event,               entry = entry,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               time_grid_approx = sort(unique(time)),               surv_form = \"exp\",               learner = \"SuperLearner\",               SL_control = list(SL.library = SL.library,                                 V = 5))  plot(fit$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a conditional survival function via local survival stacking — stackL","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"Estimate conditional survival function via local survival stacking","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"","code":"stackL(   time,   event = rep(1, length(time)),   entry = NULL,   X,   newX,   newtimes,   direction = \"prospective\",   bin_size = NULL,   time_basis = \"continuous\",   learner = \"SuperLearner\",   SL_control = list(SL.library = c(\"SL.mean\"), V = 10, method = \"method.NNLS\", stratifyCV     = FALSE),   tau = NULL )"},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. entry Study entry variable, applicable. Defaults NULL, indicating truncation. X n x p data.frame observed covariate values train estimator. newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. direction Whether data come prospective retrospective study. determines whether data treated subject left truncation right censoring (\"prospective\") right truncation alone (\"retrospective\"). bin_size Size bins discretization time. value 0 1 indicating size observed event time quantiles grid times (e.g. 0.02 creates grid 50 times evenly spaced quantile scaled). NULL, defaults every observed event time. time_basis treat time training binary classifier. Options \"continuous\" \"dummy\", meaning indicator variable included time time grid. learner binary regression algorithm use. Currently, SuperLearner supported, learners added. See algorithm-specific arguments. SL_control Named list parameters controlling Super Learner fitting process. parameters passed directly SuperLearner function. Parameters include SL.library (library algorithms include binary classification Super Learner), V (Number cross validation folds train Super Learner classifier, defaults 10), method (Method estimating coefficients Super Learner, defaults \"method.NNLS\"), stratifyCV (logical indicating whether stratify outcome SuperLearner's cross-validation scheme), obsWeights (observation weights, passed directly prediction algorithms SuperLearner). tau maximum time interest study, used retrospective conditional survival estimation. Rather dealing right truncation separately left truncation, simpler estimate survival function tau - time. Defaults NULL, case maximum study entry time chosen reference point.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"named list class stackL. S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. fit Super Learner fit binary classification stacked dataset.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"Polley E.C. van der Laan M.J. (2011). \"Super Learning Right-Censored Data\" Targeted Learning. Craig E., Zhong C., Tibshirani R. (2021). \"Survival stacking: casting survival analysis classification problem.\"","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackL(time = time,                event = event,                entry = entry,                X = X,                newX = X,                newtimes = seq(0, 15, .1),                direction = \"prospective\",                bin_size = 0.1,                time_basis = \"continuous\",                SL_control = list(SL.library = SL.library,                                  V = 5))  plot(fit$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/survML-package.html","id":null,"dir":"Reference","previous_headings":"","what":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","title":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","text":"Statistical tools analyzing time--event data using machine learning. Implements survival stacking conditional survival estimation, standardized survival function estimation current status data, methods algorithm-agnostic variable importance.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/survML-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","text":"Maintainer: Charles Wolock cwolock@gmail.com (ORCID) [copyright holder] contributors: Avi Kenny avi.kenny@gmail.com (ORCID) [contributor]","code":""},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate variable importance — vim","title":"Estimate variable importance — vim","text":"Compute estimates confidence intervals nonparametric variable importance based difference predictiveness obtained without feature interest. Designed use time--event outcomes subject right censoring may informed measured covariates.","code":""},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate variable importance — vim","text":"","code":"vim(   type,   time,   event,   X,   landmark_times = stats::quantile(time[event == 1], probs = c(0.25, 0.5, 0.75)),   restriction_time = max(time[event == 1]),   approx_times = NULL,   large_feature_vector,   small_feature_vector,   conditional_surv_generator = NULL,   conditional_surv_generator_control = NULL,   large_oracle_generator = NULL,   large_oracle_generator_control = NULL,   small_oracle_generator = NULL,   small_oracle_generator_control = NULL,   conditional_surv_preds = NULL,   large_oracle_preds = NULL,   small_oracle_preds = NULL,   cf_folds = NULL,   cf_fold_num = 5,   sample_split = TRUE,   ss_folds = NULL,   robust = TRUE,   scale_est = FALSE,   alpha = 0.05,   verbose = FALSE )"},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate variable importance — vim","text":"type Type VIM compute. Options include \"accuracy\", \"AUC\", \"Brier\", \"R-squared\" \"C-index\", \"survival_time_MSE\". time n x 1 numeric vector observed follow-times. censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. X n x p data.frame observed covariate values landmark_times Numeric vector length J1 giving landmark times estimate VIM (\"accuracy\", \"AUC\", \"Brier\", \"R-squared\"). restriction_time Maximum follow-time calculation \"C-index\" \"survival_time_MSE\". Essentially, time chosen conditional survival function identified time covariate values X present data. Choosing restriction time roughly 10% individuals remain -risk time shown work reasonably well simulations. approx_times Numeric vector length J2 giving times approximate integrals. Defaults grid 100 timepoints, evenly spaced quantile scale distribution observed event times. large_feature_vector Numeric vector giving indices features include 'large' prediction model. small_feature_vector Numeric vector giving indices features include 'small' prediction model. Must subset large_feature_vector. conditional_surv_generator function estimate conditional survival functions event censoring variables. Must take arguments (time, event, X) (training purposes) (X_holdout newtimes) (covariate values times generate predictions). Defaults generate_nuisance_predictions_stackG, pre-built generator function based stackG function. Alternatively, user can provide function argument, provide pre-computed estimates conditional_surv_preds lieu argument. conditional_surv_generator_control list arguments pass conditional_surv_generator. large_oracle_generator function estimate oracle prediction function using large_feature_vector. Must take arguments time, event, X, X_holdout, nuisance_preds. VIM types except \"C-index\", defaults generate_oracle_predictions_DR, pre-built generator function using doubly-robust pseudo-outcome regression. \"C-index\", defaults generate_oracle_predictions_boost, pre-built generator function using doubly-robust gradient boosting. Alternatively, user can provide function, provide pre-computed estimates large_oracle_preds lieu argument. large_oracle_generator_control list arguments pass large_oracle_generator. small_oracle_generator function estimate oracle prediction function using small_feature_vector. Must take arguments time, event, X, X_holdout, nuisance_preds. VIM types except \"C-index\", defaults generate_oracle_predictions_SL, pre-built generator function based regression large oracle predictions small feature vector. \"C-index\", defaults generate_oracle_predictions_boost, pre-built generator function using doubly-robust gradient boosting. Alternatively, user can provide function, provide pre-computed estimates small_oracle_preds lieu argument. small_oracle_generator_control list arguments pass small_oracle_generator. conditional_surv_preds User-provided estimates conditional survival functions event censoring variables given full covariate vector (using conditional_surv_generator functionality compute nuisance estimates). Must named list lists elements S_hat, S_hat_train, G_hat, G_hat_train. using sample splitting, list length 2K, K number cross-fitting folds (using sample splitting, list length K). element lists matrix J2 columns number rows equal either number samples kth fold (S_hat G_hat) number samples used compute nuisance estimates kth fold (S_hat_train G_hat_train). large_oracle_preds User-provided estimates oracle prediction function using large_feature_vector (using large_oracle_generator functionality compute nuisance estimates). Must named list lists elements f0_hat f0_hat_train. using sample splitting, list length 2K (using sample splitting, list length K). element lists matrix J1 columns (landmark time VIMs) 1 column (\"C-index\" \"survival_time_MSE\") number rows equal either number samples kth fold (f0_hat) number samples used compute nuisance estimates kth fold (f0_hat_train). small_oracle_preds User-provided estimates oracle prediction function using small_feature_vector (using small_oracle_generator functionality compute nuisance estimates). Must named list lists elements f0_hat f0_hat_train. using sample splitting, list length 2K (using sample splitting, list length K). element lists matrix J1 columns (landmark time VIMs) 1 column (\"C-index\" \"survival_time_MSE\") number rows equal either number samples kth fold (f0_hat) number samples used compute nuisance estimates kth fold (f0_hat_train). cf_folds Numeric vector length n giving cross-fitting folds, specifying folds explicitly. required providing pre-computed nuisance estimations — providing nuisance generator function, vim() assign folds. cf_fold_num number cross-fitting folds, providing cf_folds. Note samples-splitting, data split 2 x cf_fold_num folds (.e., cf_fold_num folds within half data). sample_split Logical indicating whether sample split. Sample-splitting required valid hypothesis testing null importance generally recommended. Defaults TRUE. ss_folds Numeric vector length n giving sample-splitting folds, specifying folds explicitly. required providing pre-computed nuisance estimations — providing nuisance generator function, vim() assign folds. robust Logical, whether use doubly-robust debiasing approach. option meant illustration purposes — left TRUE. scale_est Logical, whether force VIM estimate nonnegative. alpha level compute confidence intervals hypothesis tests. Defaults 0.05. verbose Whether print progress messages.","code":""},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate variable importance — vim","text":"Named list following elements: result Data frame giving results. See documentation individual vim_* functions details. folds named list giving cross-fitting fold IDs (cf_folds) sample-splitting fold IDs (ss_folds). approx_times vector times used approximate integrals appearing form VIM estimator. conditional_surv_preds named list containing estimated conditional event censoring survival functions. large_oracle_preds named list containing estimated large oracle prediction function. small_oracle_preds named list containing estimated small oracle prediction function.","code":""},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate variable importance — vim","text":"nuisance estimation, generally advisable use pre-built nuisance generator functions provided survML. See ”Variable importance survival analysis” vignette, package website illustration.","code":""},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate variable importance — vim","text":"Wolock C.J., Gilbert P.B., Simon N., Carone, M. (2025). \"Assessing variable importance survival analysis using machine learning.\"","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/vim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate variable importance — vim","text":"","code":"# This is a small simulation example set.seed(123) n <- 100 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # landmark times for AUC landmark_times <- c(3)  output <- vim(type = \"AUC\",               time = time,               event = event,               X = X,               landmark_times = landmark_times,               large_feature_vector = 1:2,               small_feature_vector = 2,               conditional_surv_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               large_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               small_oracle_generator_control = list(SL.library = c(\"SL.mean\", \"SL.glm\")),               cf_fold_num = 2,               sample_split = FALSE,               scale_est = TRUE)  print(output$result) #>   landmark_time       est  var_est        cil       ciu cil_1sided  p #> 1             3 0.2823303 1.407984 0.04976388 0.5148967 0.08715441 NA #>   large_predictiveness small_predictiveness vim large_feature_vector #> 1            0.8209323             0.538602 AUC                  1,2 #>   small_feature_vector #> 1                    2"},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate AUC VIM — vim_AUC","title":"Estimate AUC VIM — vim_AUC","text":"Estimate AUC VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate AUC VIM — vim_AUC","text":"","code":"vim_AUC(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   sample_split,   ss_folds,   robust = TRUE,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate AUC VIM — vim_AUC","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate AUC f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds robust Logical, whether use doubly-robust debiasing approach. option meant illustration purposes — left TRUE. scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate AUC VIM — vim_AUC","text":"data frame giving results, following columns: landmark_time Time AUC evaluated. est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate classification accuracy VIM — vim_accuracy","title":"Estimate classification accuracy VIM — vim_accuracy","text":"Estimate classification accuracy VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate classification accuracy VIM — vim_accuracy","text":"","code":"vim_accuracy(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate classification accuracy VIM — vim_accuracy","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate accuracy f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate classification accuracy VIM — vim_accuracy","text":"data frame giving results, following columns: landmark_time Time AUC evaluated. est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Brier score VIM — vim_brier","title":"Estimate Brier score VIM — vim_brier","text":"Estimate Brier score VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Brier score VIM — vim_brier","text":"","code":"vim_brier(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   ss_folds,   sample_split,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Brier score VIM — vim_brier","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate Brier score f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds ss_folds Numeric vector length n giving sample-splitting folds sample_split Logical indicating whether sample split scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Brier score VIM — vim_brier","text":"data frame giving results, following columns: landmark_time Time AUC evaluated. est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate concordance index VIM — vim_cindex","title":"Estimate concordance index VIM — vim_cindex","text":"Estimate concordance index VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate concordance index VIM — vim_cindex","text":"","code":"vim_cindex(   time,   event,   approx_times,   restriction_time,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate concordance index VIM — vim_cindex","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. restriction_time Restriction time (upper bound event times compared computing C-index) f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate concordance index VIM — vim_cindex","text":"data frame giving results, following columns: restriction_time Restriction time (upper bound event times compared computing C-index). est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate R-squared (proportion of explained variance) VIM based on event occurrence by a landmark time — vim_rsquared","title":"Estimate R-squared (proportion of explained variance) VIM based on event occurrence by a landmark time — vim_rsquared","text":"Estimate R-squared (proportion explained variance) VIM based event occurrence landmark time","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate R-squared (proportion of explained variance) VIM based on event occurrence by a landmark time — vim_rsquared","text":"","code":"vim_rsquared(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   ss_folds,   sample_split,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate R-squared (proportion of explained variance) VIM based on event occurrence by a landmark time — vim_rsquared","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate Brier score f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds ss_folds Numeric vector length n giving sample-splitting folds sample_split Logical indicating whether sample split scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate R-squared (proportion of explained variance) VIM based on event occurrence by a landmark time — vim_rsquared","text":"data frame giving results, following columns: landmark_time Time AUC evaluated. est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/vim_survival_time_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate restricted predicted survival time MSE VIM — vim_survival_time_mse","title":"Estimate restricted predicted survival time MSE VIM — vim_survival_time_mse","text":"Estimate restricted predicted survival time MSE VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_survival_time_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate restricted predicted survival time MSE VIM — vim_survival_time_mse","text":"","code":"vim_survival_time_mse(   time,   event,   approx_times,   restriction_time,   f_hat,   fs_hat,   S_hat,   G_hat,   cf_folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_survival_time_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate restricted predicted survival time MSE VIM — vim_survival_time_mse","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. restriction_time restriction time f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) cf_folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_survival_time_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate restricted predicted survival time MSE VIM — vim_survival_time_mse","text":"data frame giving results, following columns: restriction_time Restriction time (upper bound event times compared computing restricted survival time). est VIM point estimate. var_est Estimated variance VIM estimate. cil Lower bound VIM confidence interval. ciu Upper bound VIM confidence interval. cil_1sided Lower bound one-sided confidence interval. p p-value corresponding hypothesis test null importance. large_predictiveness Estimated predictiveness large oracle prediction function. small_predictiveness Estimated predictiveness small oracle prediction function. vim VIM type. large_feature_vector Group features available large oracle prediction function. small_feature_vector Group features available small oracle prediction function.","code":""},{"path":[]},{"path":[]},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-120","dir":"Changelog","previous_headings":"","what":"survML 1.2.0","title":"survML 1.2.0","text":"CRAN release: 2024-10-30","code":""},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-120-1","dir":"Changelog","previous_headings":"","what":"survML 1.2.0","title":"survML 1.2.0","text":"CRAN release: 2024-10-30 Added variable importance current status isotonic regression functions; changes affect existing stackG stackL functions. Fixed bug stackG threw error censoring. Added cumulative hazard estimates stackG output.","code":""},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-110","dir":"Changelog","previous_headings":"","what":"survML 1.1.0","title":"survML 1.1.0","text":"CRAN release: 2024-03-17 Added gam SUGGESTS order allow SuperLearner package make corresponding change without breaking vignettes. Added time_grid_fit option main stackG function order allow flexibility choosing time grids. Minor bug fixes.","code":""},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-100","dir":"Changelog","previous_headings":"","what":"survML 1.0.0","title":"survML 1.0.0","text":"CRAN release: 2023-07-08 Initial CRAN submission.","code":""}]
