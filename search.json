[{"path":"https://cwolock.github.io/survML/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU GENERAL PUBLIC LICENSE","title":"GNU GENERAL PUBLIC LICENSE","text":"Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU GENERAL PUBLIC LICENSE","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: assert copyright software, offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU GENERAL PUBLIC LICENSE","text":"License refers version 3 GNU General Public License. Copyright also means copyright-like laws apply kinds works, semiconductor masks. Program refers copyrightable work licensed License. licensee addressed . Licensees recipients may individuals organizations. modify work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called modified version earlier work work based earlier work. covered work means either unmodified Program work based Program. propagate work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. convey work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays Appropriate Legal Notices extent includes convenient prominently visible feature displays appropriate copyright notice, tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU GENERAL PUBLIC LICENSE","text":"source code work means preferred form work making modifications . Object code means non-source form work. Standard Interface means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. System Libraries executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. Major Component, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . Corresponding Source work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU GENERAL PUBLIC LICENSE","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU GENERAL PUBLIC LICENSE","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 keep intact notices. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called aggregate compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU GENERAL PUBLIC LICENSE","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. User Product either consumer product, means tangible personal property normally used personal, family, household purposes, anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, normally used refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. Installation Information User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU GENERAL PUBLIC LICENSE","text":"Additional permissions terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered restrictions within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU GENERAL PUBLIC LICENSE","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated provisionally, unless copyright holder explicitly finally terminates license, permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU GENERAL PUBLIC LICENSE","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU GENERAL PUBLIC LICENSE","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. entity transaction transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU GENERAL PUBLIC LICENSE","text":"contributor copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s contributor version. contributor’s essential patent claims patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, control includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, patent license express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). grant patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either cause Corresponding Source available, arrange deprive benefit patent license particular work, arrange, manner consistent requirements License, extend patent license downstream recipients. Knowingly relying means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license discriminatory include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license connection copies covered work conveyed (copies made copies), primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU GENERAL PUBLIC LICENSE","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU GENERAL PUBLIC LICENSE","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License later version applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU GENERAL PUBLIC LICENSE","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU GENERAL PUBLIC LICENSE","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU GENERAL PUBLIC LICENSE","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee.","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"END OF TERMS AND CONDITIONS","what":"How to Apply These Terms to Your New Programs","title":"GNU GENERAL PUBLIC LICENSE","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least copyright line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use box. also get employer (work programmer) school, , sign copyright disclaimer program, necessary. information , apply follow GNU GPL, see http://www.gnu.org/licenses/. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read http://www.gnu.org/philosophy/--lgpl.html.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'. This is free software, and you are welcome to redistribute it under certain conditions; type `show c' for details."},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"survML package implements two methods estimating conditional survival function using --shelf machine learning. first, called global survival stacking performed using stackG() function, involves decomposing conditional cumulative hazard function regression functions depending observed data. second, called local survival stacking discrete-time hazard estimation, involves discretizing time estimating probability event interest within discrete time period. procedure implemented stackL() function. functions can used left-truncated, right-censored data (commonly seen prospective studies) right-truncated data (commonly seen retrospective studies). details method, well examples, follow.","code":""},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"global-survival-stacking","dir":"Articles","previous_headings":"","what":"Global survival stacking","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"basic survival analysis setting right-censored data (simplicity, don’t discuss truncation ), ideal data individual consist covariate vector XX, event time TT, censoring time CC. observed data consist XX, observed follow-time Y:=min(T,C)Y:=\\text{min}(T,C), event indicator Δ:=(T≤C)\\Delta := (T \\leq C). Global survival stacking requires three components: (1) conditional probability Δ=1\\Delta = 1 given XX, (2) CDF YY given XX among among censored subjects, (3) CDF YY given XX among uncensored subjects. three can estimated using standard binary regression classification methods. Estimating (1) standard binary regression problem. use pooled binary regression estimate (2) (3). essence, time tt user-specified grid, CDF binary regression using outcome (Y≤t)(Y \\leq t). data sets tt combined single, pooled data set, including tt covariate. Currently, survML allows Super Learner used binary regression, learners added future versions. stackG function performs global survival stacking. important user-specified arguments described : bin_size: size time grid used estimating (2) (3). cases, finer grid performs better coarser grid, increased computational cost. recommend using fine grid computational resources time allow. simulations, grid 40 time points performed similarly grid every observed follow-time. Bin size given quantile terms; bin_size = 0.025 use times corresponding quantiles {0,0.025,0.05,…,0.975,1}\\{0, 0.025, 0.05, \\dots, 0.975, 1\\}. NULL, grid every observed time used. time_basis: time variable tt included pooled data set. default continuous (.e., include time -). also possible include dummy variable time grid (.e., treat time factor variable) using option dummy. learner: Currently, supported option SuperLearner. SL_control: named list arguments passed directly SuperLearner() function. SL.library gives library algorithms included Super Learner binary regression. argument vector algorithm names, can either default algorithms included SuperLearner package, user-specified algorithms. See SuperLearner package documentation information.","code":""},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"example","dir":"Articles","previous_headings":"Global survival stacking","what":"Example","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"’s small example applying stackG simulated data. can plot fitted versus true conditional survival various times one particular individual data set:  stackG function simultaneously produces estimates conditional censoring distribution. may useful, example, producing inverse probability censoring (IPCW) weights.","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  time <- pmin(T, C) event <- as.numeric(T <= C)  # note that this a very small library, just for demonstration SL.library <- c(\"SL.mean\", \"SL.glm\", \"SL.gam\")  fit <- stackG(time = time,               event = event,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               time_grid_approx = sort(unique(time)),               surv_form = \"exp\",               SL_control = list(SL.library = SL.library,                                 V = 5)) plot_dat <- data.frame(fitted = fit$S_T_preds[1,],                         true = S0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Global survival stacking example (event time distribution)\")  p plot_dat <- data.frame(fitted = fit$S_C_preds[1,],                         true = G0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Global survival stacking example (censoring time distribution)\")  p"},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"local-survival-stacking","dir":"Articles","previous_headings":"","what":"Local survival stacking","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"discrete time--event variables, hazard function single time conditional probability whose estimation can framed binary regression problem: among experienced event time tt, proportion experience outcome time? Local survival stacking assumes discrete survival process based estimating conditional event probability time user-specified grid. binary regressions estimated jointly “stacking” data sets corresponding times grid. idea dates back least work Polley van der Laan (2011) also recently described Craig et al. (2021).","code":""},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"example-1","dir":"Articles","previous_headings":"Local survival stacking","what":"Example","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"","code":"fit <- stackL(time = time,               event = event,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               SL_control = list(SL.library = SL.library,                                 V = 5)) plot_dat <- data.frame(fitted = fit$S_T_preds[1,],                         true = S0(t =  seq(0, 15, .1), X[1,]))  p <- ggplot(data = plot_dat, mapping = aes(x = true, y = fitted)) +    geom_point() +    geom_abline(slope = 1, intercept = 0, color = \"red\") +    theme_bw() +    ylab(\"fitted\") +   xlab(\"true\") +    ggtitle(\"Local survival stacking example\")  p"},{"path":"https://cwolock.github.io/survML/articles/conditional_survival.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating a conditional survival function using off-the-shelf machine learning tools","text":"details global survival stacking, please see following paper: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). Local survival stacking described : Eric C. Polley Mark J. van der Laan. “Super Learning Right-Censored Data” Targeted Learning (2011). Erin Craig, Chenyang Zhong, Robert Tibshirani. “Survival stacking: casting survival analysis classification problem.” arXiv:2107.13480.","code":""},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Assessing variable importance in survival analysis using machine learning","text":"survML package includes functions can used estimate model-free, algorithm-agnostic variable importance outcome interest subject right censoring. Specifically, functionality aimed estimating intrinsic variable importance, population-level predictiveness potential feature group features. Suppose access vector XX features, wish use make prediction involving TT, time--event outcome. use CC denote right censoring variable. observed data given (X,Y,Δ)(X, Y, \\Delta), Δ:=(T≤C)\\Delta := (T \\leq C) Y:=min(T,C)Y := \\text{min}(T, C). index set ss, use XsX_s denote elements XX index ss X−sX_{-s} complement. given prediction task (say, estimating probability TT smaller landmark time τ\\tau) prediction function ff, require measure predictiveness. let V(f,P0)V(f, P_0) denote predictiveness ff sampling distribution P0P_0. define f0,sf_{0,s} oracle prediction function excluding features index ss; best possible prediction function, according VV, uses X−sX_{-s}. intrinsic variable importance, consider nested index sets r⊂sr \\subset s define importance Xs\\rX_{s \\setminus r} relative XsX_s V(f0,r,P0)−V(f0,s,P0)V(f_{0,r}, P_0) - V(f_{0,s}, P_0); difference maximum achievable predictiveness rr excluded compared ss excluded. refer parameter variable importance measure (VIM). Due right censoring, VIM estimation procedure requires estimates conditional survival functions TT CC given XX, define pointwise S0(t∣x):=P0(T>t∣X=x)S_0(t \\mid x) := P_0(T > t \\mid X = x) G0(t∣x):=P0(C>t∣X=x)G_0(t \\mid x) := P_0(C > t \\mid X = x), respectively. functions must estimated interval (0,τ](0, \\tau] may obtained conditional survival estimation algorithm. may simple Cox proportional hazards model (Cox, 1972) parametric survival regression model, complex stacked regression procedure survival Super Learner (Westling et al., 2023) global survival stacking (Wolock et al., 2024). also require estimates oracle prediction functions f0,rf_{0,r} f0,sf_{0,s}, whose exact form depends chosen predictiveness measure. several commonly used measures, oracle prediction functions can written terms S0(⋅∣x)S_0(\\cdot \\mid x). form oracle prediction function measures included survML given Table XX.","code":""},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"example-predicting-recurrence-free-survival-time-in-cancer-patients","dir":"Articles","previous_headings":"","what":"Example: Predicting recurrence-free survival time in cancer patients","title":"Assessing variable importance in survival analysis using machine learning","text":"example, consider estimating variable importance predicting recurrence-free survival using gbsg dataset survival package. Kaplan-Meier estimate survival curve dataset shown .  consider time-varying AUC importance using landmark times 500, 1000, 1500 2000 days. first step prepare data. use dummy coding factors. means assess importance tumor grade, example, three levels, create two dummy variables called tumgrad2 tumgrad3 consider single feature group. also consider feature groups defined tumor-level features patient-level features. Next, write functions estimate relevant nuisance parameters.","code":"data(cancer) km_fit <- survfit(Surv(rfstime, status) ~ 1, data = gbsg) plot(km_fit, xlab = \"Time (days)\", ylab = \"Recurrence-free survival probability\") ### variables of interest # rfstime - recurrence-free survival # status - censoring indicator # hormon - hormonal therapy treatment indicator # age - in years # meno - 1 = premenopause, 2 = post # size - tumor size in mm # grade - factor 1,2,3 # nodes - number of positive nodes # pgr - progesterone receptor in fmol # er - estrogen receptor in fmol  # create dummy variables and clean data gbsg$tumgrad2 <- ifelse(gbsg$grade == 2, 1, 0) gbsg$tumgrad3 <- ifelse(gbsg$grade == 3, 1, 0) gbsg <- gbsg %>% na.omit() %>% select(-c(pid, grade))  time <- gbsg$rfstime event <- gbsg$status X <- gbsg %>% select(-c(rfstime, status)) # remove outcome   # find column indices of features/feature groups X_names <- names(X) age_index <- paste0(which(X_names == \"age\")) meno_index <- paste0(which(X_names == \"meno\")) size_index <- paste0(which(X_names == \"size\")) nodes_index <- paste0(which(X_names == \"nodes\")) pgr_index <- paste0(which(X_names == \"pgr\")) er_index <- paste0(which(X_names == \"er\")) hormon_index <- paste0(which(X_names == \"hormon\")) grade_index <- paste0(which(X_names %in% c(\"tumgrad2\", \"tumgrad3\")), collapse = \",\") tum_index <- paste0(which(X_names %in% c(\"size\", \"nodes\", \"pgr\", \"er\", \"tumgrad2\", \"tumgrad3\")),                     collapse = \",\") person_index <- paste0(which(X_names %in% c(\"age\", \"meno\", \"hormon\")), collapse = \",\")  feature_group_names <- c(\"age\", \"meno.\", \"size\", \"nodes\",                          \"prog.\", \"estro.\", \"hormone\",                           \"grade\") feature_groups <- c(age_index, meno_index, size_index, nodes_index,                     pgr_index, er_index, hormon_index, grade_index)  # consider joint importance of all tumor-level and person-level features feature_group_names2 <- c(\"tumor\", \"person\") feature_groups2 <- c(tum_index, person_index) # estimate conditional survival functions generate_full_predictions <- function(time,                                        event,                                        X,                                        X_holdout,                                        landmark_times,                                        approx_times,                                       SL.library){        surv_out <- survML::stackG(time = time,                                event = event,                                X = X,                                newX = rbind(X_holdout, X),                                newtimes = approx_times,                                time_grid_approx = approx_times,                                bin_size = 0.05,                                time_basis = \"continuous\",                                surv_form = \"PI\",                                SL_control = list(SL.library = SL.library,                                                  V = 5))     S_hat <- surv_out$S_T_preds[1:nrow(X_holdout),]     G_hat <- surv_out$S_C_preds[1:nrow(X_holdout),]     f_hat <- S_hat[,which(approx_times %in% landmark_times),drop=FALSE]     S_hat_train <- surv_out$S_T_preds[(nrow(X_holdout)+1):(nrow(X_holdout)+nrow(X)),]     G_hat_train <- surv_out$S_C_preds[(nrow(X_holdout)+1):(nrow(X_holdout)+nrow(X)),]     f_hat_train <- S_hat_train[,which(approx_times %in% landmark_times),drop=FALSE]   return(list(S_hat = S_hat,               G_hat = G_hat,               f_hat = f_hat,               f_hat_train = f_hat_train,               S_hat_train = S_hat_train,               G_hat_train = G_hat_train)) }  # estimate residual oracle prediction function by regressing full predictions on reduced feature vector generate_reduced_predictions <- function(f_hat,                                          X_reduced,                                          X_reduced_holdout,                                          landmark_times,                                          SL.library){      long_dat <- data.frame(f_hat = f_hat, X_reduced)   long_new_dat <- data.frame(X_reduced_holdout)   reduced_fit <- SuperLearner::SuperLearner(Y = long_dat$f_hat,                                             X = long_dat[,2:ncol(long_dat),drop=FALSE],                                             family = stats::gaussian(),                                             SL.library = SL.library,                                             method = \"method.NNLS\",                                             verbose = FALSE)   fs_hat <- matrix(predict(reduced_fit, newdata = long_new_dat)$pred,                    nrow = nrow(X_reduced_holdout),                    ncol = length(landmark_times))      return(list(fs_hat = fs_hat)) }  # produce cross-fitted full predictions CV_generate_full_predictions <- function(time,                                          event,                                          X,                                          landmark_times,                                          approx_times,                                          folds,                                          sample_split,                                          SL.library,                                          DR_pred){   .V <- length(unique(folds))   CV_full_preds_train <- list()   CV_full_preds <- list()   CV_S_preds <- list()   CV_S_preds_train <- list()   CV_G_preds <- list()      for (j in 1:.V){          time_train <- time[folds != j]     event_train <- event[folds != j]     X_train <- X[folds != j,]          X_holdout <- X[folds == j,]     full_preds <- generate_full_predictions(time = time_train,                                             event = event_train,                                             X = X_train,                                             X_holdout = X_holdout,                                             landmark_times = landmark_times,                                             approx_times = approx_times,                                             SL.library = SL.library)     if (!DR_pred){         CV_full_preds_train[[j]] <- full_preds$f_hat_train         CV_full_preds[[j]] <- full_preds$f_hat       } else{ # doubly-robust version --- see below         DR_preds <- generate_DR_predictions(           time = time_train,           event = event_train,           X = X_train,           X_holdout = X_holdout,           landmark_times = landmark_times,           approx_times = approx_times,           S_hat = full_preds$S_hat_train,           G_hat = full_preds$G_hat_train,           SL.library = SL.library         )         CV_full_preds_train[[j]] <- DR_preds$f_hat_train         CV_full_preds[[j]] <- DR_preds$f_hat       }     CV_S_preds[[j]] <- full_preds$S_hat     CV_G_preds[[j]] <- full_preds$G_hat     CV_S_preds_train[[j]] <- full_preds$S_hat_train   }    return(list(CV_full_preds_train = CV_full_preds_train,               CV_full_preds = CV_full_preds,               CV_S_preds = CV_S_preds,               CV_S_preds_train = CV_S_preds_train,               CV_G_preds = CV_G_preds)) }  # produce cross-fitted reduced predictions CV_generate_reduced_predictions <- function(time,                                             event,                                             X,                                             landmark_times,                                             folds,                                             indx,                                             sample_split,                                             full_preds_train,                                             SL.library){   .V <- length(unique(folds))   CV_reduced_preds <- list()      for (j in 1:.V){          X_reduced_train <- X[folds != j,-indx,drop=FALSE]     X_reduced_holdout <- X[folds == j,-indx,drop=FALSE]          preds_j <- matrix(NA, nrow = nrow(X_reduced_holdout), ncol = length(landmark_times))     for (t in landmark_times){       outcomes <- full_preds_train[[j]][,which(landmark_times == t)]       reduced_preds <- generate_reduced_predictions(f_hat = outcomes,                                                     X_reduced = X_reduced_train,                                                     X_reduced_holdout = X_reduced_holdout,                                                     landmark_times = t,                                                     SL.library = SL.library)              preds_j[,which(landmark_times == t)] <- reduced_preds$fs_hat     }          CV_reduced_preds[[j]] <- preds_j   }      return(CV_reduced_preds) }"},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"estimating-subtractive-variable-importance","dir":"Articles","previous_headings":"Example: Predicting recurrence-free survival time in cancer patients","what":"Estimating subtractive variable importance","title":"Assessing variable importance in survival analysis using machine learning","text":"First, consider importance feature groups relative full feature vector. call subtractive variable importance — features interest subtracted full feature vector, importance measured resulting loss predictiveness. Note censoring may informed covariates part current reduced feature set, estimate residual oracle prediction function regressing full oracle predictions reduced feature set, rather directly estimating conditional survival function using reduced feature set. reduce runtime, use small Super Learner library. actual analyses, generally good idea use larger library learners.","code":"# super learner library for global survival stacking SL.library <- c(\"SL.mean\", \"SL.glm\")  # landmark times for AUC landmark_times <- c(500, 1000, 1500, 2000)  # set up cross-fitting and sample-splitting folds cf_fold_num <- 2 ss_fold_num <- 2*cf_fold_num V <- ss_fold_num folds <- sample(rep(seq_len(V), length = nrow(gbsg))) # 2V of them ss_folds <- c(rep(1, V/2), rep(2, V/2)) ss_folds <- as.numeric(folds %in% which(ss_folds == 2))  # approximation time grid for integrals  approx_times <- sort(unique(c(time[event == 1 & time <= max(landmark_times)],                                landmark_times)))  # generate nuisance estimates V0_preds <- CV_generate_full_predictions(time = time,                                          event = event,                                          X = X,                                          landmark_times = landmark_times,                                          approx_times = approx_times,                                          folds = folds,                                          sample_split = TRUE,                                          SL.library = SL.library,                                          DR_pred = FALSE)  CV_full_preds <- V0_preds$CV_full_preds CV_full_preds_train <- V0_preds$CV_full_preds_train CV_S_preds <- V0_preds$CV_S_preds CV_S_preds_train <- V0_preds$CV_S_preds_train CV_G_preds <- V0_preds$CV_G_preds  # iterate over feature groups for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])    # estimate residual oracle prediction function for this feature group   CV_reduced_preds <- CV_generate_reduced_predictions(time = time,                                               event = event,                                               X = X,                                               landmark_times = landmark_times,                                               folds = folds,                                               sample_split = sample_split,                                               indx = indx,                                               full_preds_train = CV_full_preds_train,                                               SL.library = SL.library)   # estimate VIM - note the oracle for AUC is the conditional cdf, not survival function,    # so need to take 1 - S(tau | x)   output <- vim_AUC(time = time,                     event = event,                     approx_times = approx_times,                     landmark_times = landmark_times,                     f_hat = lapply(CV_full_preds, function(x) 1-x),                     fs_hat = lapply(CV_reduced_preds, function(x) 1-x),                     S_hat = CV_S_preds,                     G_hat = CV_G_preds,                     folds = folds,                     ss_folds = ss_folds,                     sample_split = TRUE,                     scale_est = TRUE)      output$vim <- \"AUC\"   output$indx <- rep(indx_char, nrow(output))   output$indx_name <- rep(indx_name, nrow(output))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output)   } else{     pooled_output <- output   } }  # plot results p_auc <- pooled_output %>%    mutate(landmark_time = factor(landmark_time,                                 levels = c(500, 1000, 1500, 2000),                                 labels = c(\"500 days\", \"1000 days\", \"1500 days\", \"2000 days\"))) %>%   arrange(landmark_time, est) %>%   mutate(Order = row_number()) %>%   {ggplot(., aes(x = est, y = Order)) +       geom_errorbarh(aes(xmin = cil, xmax = ciu)) +       geom_point() +       theme_bw() +       xlab(\"Estimated importance\") +       ylab(\"Feature group\") +       xlim(c(0,0.3)) +       scale_y_continuous(         breaks = .$Order,         labels = .$indx_name,       ) +        facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +        ggtitle(\"Subtractive AUC variable importance\")+       theme(strip.background = element_blank(),             strip.placement = \"outside\")   } p_auc # repeat the analysis for feature groups for (i in 1:length(feature_group_names2)){   indx_char <- feature_groups2[i]   indx_name <- feature_group_names2[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])    CV_reduced_preds <- CV_generate_reduced_predictions(time = time,                                               event = event,                                               X = X,                                               landmark_times = landmark_times,                                               folds = folds,                                               sample_split = sample_split,                                               indx = indx,                                               full_preds_train = CV_full_preds_train,                                               SL.library = SL.library)   output <- vim_AUC(time = time,                     event = event,                     approx_times = approx_times,                     landmark_times = landmark_times,                     f_hat = lapply(CV_full_preds, function(x) 1-x),                     fs_hat = lapply(CV_reduced_preds, function(x) 1-x),                     S_hat = CV_S_preds,                     G_hat = CV_G_preds,                     folds = folds,                     ss_folds = ss_folds,                     sample_split = TRUE,                     scale_est = TRUE)    output$vim <- \"AUC\"   output$indx <- rep(indx_char, nrow(output))   output$indx_name <- rep(indx_name, nrow(output))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output)   } else{     pooled_output <- output   } }  p_auc <- pooled_output %>%   mutate(landmark_time = factor(landmark_time,                                 levels = c(500, 1000, 1500, 2000),                                 labels = c(\"500 days\", \"1000 days\", \"1500 days\", \"2000 days\"))) %>%   arrange(landmark_time, est) %>%   mutate(Order = row_number()) %>%   {ggplot(., aes(x = est, y = Order)) +       geom_errorbarh(aes(xmin = cil, xmax = ciu)) +       geom_point() +       theme_bw() +       xlab(\"Estimated importance\") +       ylab(\"Feature group\") +       xlim(c(0,0.5)) +       scale_y_continuous(         breaks = .$Order,         labels = .$indx_name,       ) +       facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +       ggtitle(\"Subtractive AUC variable importance (groups)\")+       theme(strip.background = element_blank(),             strip.placement = \"outside\")   } p_auc"},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"estimating-additive-variable-importance","dir":"Articles","previous_headings":"Example: Predicting recurrence-free survival time in cancer patients","what":"Estimating additive variable importance","title":"Assessing variable importance in survival analysis using machine learning","text":"Next, consider importance tumor-level features relative baseline set person-level features. call additive variable importance — feature interest added baseline set features, importance measured resulting gain predictiveness. analysis, “full” oracle predictions include baseline features plus feature interest, “residual” oracle predictions include baseline features. Note full residual oracle prediction functions analysis estimated regressing conditional survival function estimates given features relevant reduced feature set. subtractive analysis, step necessary account censoring may informed covariates, even included current set predictors.","code":"# For additive importance, the \"reduced\" model uses only person-level (baseline) features # The \"full\" model uses baseline + feature of interest # We wrote generate_reduced_predictions() to leave out the \"indx\" argument. Need to keep that in mind! size_index <- paste0(c(size_index, person_index), collapse = \",\") nodes_index <- paste0(c(nodes_index, person_index), collapse = \",\") pgr_index <- paste0(c(pgr_index, person_index), collapse = \",\") er_index <- paste0(c(er_index, person_index), collapse = \",\") grade_index <- paste0(c(grade_index, person_index), collapse = \",\")  feature_group_names <- c(\"size\", \"nodes\", \"prog.\", \"estro.\", \"grade\") feature_groups <- c(size_index, nodes_index,                     pgr_index, er_index, grade_index)  CV_reduced_preds <- CV_generate_reduced_predictions(time = time,                                                     event = event,                                                     X = X,                                                     landmark_times = landmark_times,                                                     folds = folds,                                                     sample_split = sample_split,                                                     indx = as.numeric(strsplit(tum_index, split = \",\")[[1]]),                                                     full_preds_train = CV_full_preds_train,                                                     SL.library = SL.library)  for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      all_indx <- 1:ncol(X)   # leave out features *not* in indx for additive importance   indx <- all_indx[-which(all_indx %in% indx)]      CV_full_preds <- CV_generate_reduced_predictions(time = time,                                                    event = event,                                                    X = X,                                                    landmark_times = landmark_times,                                                    folds = folds,                                                    sample_split = sample_split,                                                    indx = indx,                                                    full_preds_train = CV_full_preds_train,                                                    SL.library = SL.library)   output <- vim_AUC(time = time,                     event = event,                     approx_times = approx_times,                     landmark_times = landmark_times,                     f_hat = lapply(CV_full_preds, function(x) 1-x),                     fs_hat = lapply(CV_reduced_preds, function(x) 1-x),                     S_hat = CV_S_preds,                     G_hat = CV_G_preds,                     folds = folds,                     ss_folds = ss_folds,                     sample_split = TRUE,                     scale_est = TRUE)      output$vim <- \"AUC\"   output$indx <- rep(indx_char, nrow(output))   output$indx_name <- rep(indx_name, nrow(output))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output)   } else{     pooled_output <- output   } }  p_auc <- pooled_output %>%     mutate(landmark_time = factor(landmark_time,                                 levels = c(500, 1000, 1500, 2000),                                 labels = c(\"500 days\", \"1000 days\", \"1500 days\", \"2000 days\"))) %>%   arrange(landmark_time, est) %>%   mutate(Order = row_number()) %>%   {ggplot(., aes(x = est, y = Order)) +       geom_errorbarh(aes(xmin = cil, xmax = ciu)) +       geom_point() +       theme_bw() +       xlab(\"Estimated importance\") +       ylab(\"Feature group\") +       xlim(c(0,0.4)) +       scale_y_continuous(         breaks = .$Order,         labels = .$indx_name,       ) +        facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +        ggtitle(\"Additive AUC variable importance\")+       theme(strip.background = element_blank(),             strip.placement = \"outside\")#,   } p_auc"},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"adjustment-variables","dir":"Articles","previous_headings":"","what":"Adjustment variables","title":"Assessing variable importance in survival analysis using machine learning","text":"may covariates thought influence TT CC scientific interest terms variable importance. (may think covariates analogous confounders causal inference setting.) important adjust variables analyses. gbsg analysis, example, may wish adjust person-level covariates age, menopausal status, hormone treatment therapy, assess variable importance using predictiveness tumor-level covariates. use rr denote index set adjustment variables, use ss denote index set variables interest. importance XsX_s relative X−rX_{-r} (.e., full covariate vector excluding adjustment variables) given V(f0,r,P0)−V(f0,(r∪s),P0)V(f_{0, r}, P_0) - V(f_{0, (r \\cup s)}, P_0). usual, many possible approaches estimating f0,rf_{0,r} f0,(r∪s)f_{0,(r \\cup s)}, depending explicit form. case AUC predictiveness, can simply estimate prediction models f0,rf_{0,r} f0,(r∪s)f_{0,(r \\cup s)} (1) estimating full oracle prediction function f0f_0, (2) generating predictions individuals training data, (3) regressing predictions appropriate reduced covariate vector. , repeat subtractive variable importance analysis adjusting person-level covariates.","code":"size_index <- paste0(c(size_index, person_index), collapse = \",\") nodes_index <- paste0(c(nodes_index, person_index), collapse = \",\") pgr_index <- paste0(c(pgr_index, person_index), collapse = \",\") er_index <- paste0(c(er_index, person_index), collapse = \",\") grade_index <- paste0(c(grade_index, person_index), collapse = \",\")  feature_group_names <- c(\"size\", \"nodes\", \"prog.\", \"estro.\", \"grade\") feature_groups <- c(size_index, nodes_index,                     pgr_index, er_index, grade_index)  # in this analysis, \"full\" predictions are obtained by regressing the conditional survival # function estimates given all features on the tumor-level features, i.e., leaving out # person features CV_full_preds <- CV_generate_reduced_predictions(time = time,                                                     event = event,                                                     X = X,                                                     landmark_times = landmark_times,                                                     folds = folds,                                                     sample_split = sample_split,                                                     indx = as.numeric(strsplit(person_index, split = \",\")[[1]]),                                                     full_preds_train = CV_full_preds_train,                                                     SL.library = SL.library)  for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])      CV_reduced_preds <- CV_generate_reduced_predictions(time = time,                                                    event = event,                                                    X = X,                                                    landmark_times = landmark_times,                                                    folds = folds,                                                    sample_split = sample_split,                                                    indx = indx,                                                    full_preds_train = CV_full_preds_train,                                                    SL.library = SL.library)   output <- vim_AUC(time = time,                     event = event,                     approx_times = approx_times,                     landmark_times = landmark_times,                     f_hat = lapply(CV_full_preds, function(x) 1-x),                     fs_hat = lapply(CV_reduced_preds, function(x) 1-x),                     S_hat = CV_S_preds,                     G_hat = CV_G_preds,                     folds = folds,                     ss_folds = ss_folds,                     sample_split = TRUE,                     scale_est = TRUE)      output$vim <- \"AUC\"   output$indx <- rep(indx_char, nrow(output))   output$indx_name <- rep(indx_name, nrow(output))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output)   } else{     pooled_output <- output   } }  p_auc <- pooled_output %>%     mutate(landmark_time = factor(landmark_time,                                 levels = c(500, 1000, 1500, 2000),                                 labels = c(\"500 days\", \"1000 days\", \"1500 days\", \"2000 days\"))) %>%   arrange(landmark_time, est) %>%   mutate(Order = row_number()) %>%   {ggplot(., aes(x = est, y = Order)) +       geom_errorbarh(aes(xmin = cil, xmax = ciu)) +       geom_point() +       theme_bw() +       xlab(\"Estimated importance\") +       ylab(\"Feature group\") +       xlim(c(0,0.4)) +       scale_y_continuous(         breaks = .$Order,         labels = .$indx_name,       ) +        facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +        ggtitle(\"Adjusted subtractive AUC variable importance\")+       theme(strip.background = element_blank(),             strip.placement = \"outside\")#,   } p_auc"},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"doubly-robust-estimation","dir":"Articles","previous_headings":"","what":"Doubly-robust estimation","title":"Assessing variable importance in survival analysis using machine learning","text":"VIM estimation procedure implemented survML doubly-robust respect conditional time--event survival function S0S_0 conditional censoring survival function G0G_0: Roughly speaking, long one two nuisance functions estimated well, VIM estimator tend probability true population VIM sample size increases. many cases, oracle prediction functions f0f_0 f0,sf_{0,s} can estimated doubly-robust manner. example, AUC Brier score VIMs evaluated landmark time τ\\tau, oracle prediction function simply S0(τ∣x)S_0(\\tau \\mid x). pseudo-outcome approach Rubin van der Laan (2007) can used construct doubly-robust estimator conditional survival function single time-point, computational cost performing additional regression step. Given initial estimates S0S_0 G0G_0, following code constructs doubly-robust estimate S0(τ∣x)S_0(\\tau \\mid x) using Super Learner. doubly-robust estimator f0f_0 can regressed reduced covariate vector give doubly-robust estimator f0,sf_{0,s}. doubly-robust estimated oracle prediction functions can used usual manner estimate variable importance. , repeat original subtractive analysis using doubly-robust pseudo-outcome approach.","code":"generate_DR_predictions <- function(time,                                     event,                                     X,                                     X_holdout,                                     landmark_times,                                     approx_times,                                     S_hat,                                     G_hat,                                     SL.library){    DR_predictions <- matrix(NA, nrow = nrow(X_holdout), ncol = length(landmark_times))   DR_predictions_train <- matrix(NA, nrow = nrow(X), ncol = length(landmark_times))   for (i in 1:length(landmark_times)){     tau <- landmark_times[i]     Delta_t <- event * (time <= tau) + (time > tau)     Y_t <- pmin(time, tau)      # calculate m_0 at a specific time t     calc_one <- function(t){       if (approx_times[t] >= tau){         m <-  rep(1, nrow(S_hat))       } else{         m <- S_hat[,which(approx_times == tau)]/S_hat[,t]       }       return(m)     }     # calculate m_0 over the whole grid     ms <- matrix(unlist(lapply(1:length(approx_times), FUN = calc_one)),                  nrow = length(time))      m_Y <- apply(X = matrix(1:length(Y_t)), MARGIN = 1,                  FUN = function(x) ms[x,which.min(abs(approx_times - Y_t[x]))])      G_hat_Y <- apply(X = matrix(1:length(Y_t)), MARGIN = 1,                      FUN = function(x) G_hat[x,which.min(abs(approx_times - Y_t[x]))])      term1 <- Delta_t*(Y_t >= tau) / G_hat_Y      term2 <- (1 - Delta_t) * m_Y / G_hat_Y      int.vals <- t(sapply(1:length(time), function(j) {       vals <- diff(1/G_hat[j,])* ms[j,-ncol(ms)]       if(any(approx_times[-1] > Y_t[j])){         vals[approx_times[-1] > Y_t[j]] <- 0       }       sum(vals)     }))      term3 <- t(int.vals)      DR_pseudo_outcome <- term1 + term2 - term3      SL_fit <- SuperLearner::SuperLearner(Y = DR_pseudo_outcome,                                          X = X,                                          family = stats::gaussian(),                                          SL.library = SL.library,                                          method = \"method.NNLS\",                                          verbose = FALSE)     SL_preds <- predict(SL_fit, newdata = X_holdout)$pred     DR_predictions[,i] <- SL_preds     SL_preds_train <- predict(SL_fit, newdata = X)$pred     DR_predictions_train[,i] <- SL_preds_train    }   return(list(f_hat = DR_predictions, f_hat_train = DR_predictions_train)) } # reset feature groups age_index <- paste0(which(X_names == \"age\")) meno_index <- paste0(which(X_names == \"meno\")) size_index <- paste0(which(X_names == \"size\")) nodes_index <- paste0(which(X_names == \"nodes\")) pgr_index <- paste0(which(X_names == \"pgr\")) er_index <- paste0(which(X_names == \"er\")) hormon_index <- paste0(which(X_names == \"hormon\")) grade_index <- paste0(which(X_names %in% c(\"tumgrad2\", \"tumgrad3\")), collapse = \",\")  feature_group_names <- c(\"age\", \"meno.\", \"size\", \"nodes\",                          \"prog.\", \"estro.\", \"hormone\",                           \"grade\") feature_groups <- c(age_index, meno_index, size_index, nodes_index,                     pgr_index, er_index, hormon_index, grade_index)  # generate nuisance estimates V0_preds <- CV_generate_full_predictions(time = time,                                          event = event,                                          X = X,                                          landmark_times = landmark_times,                                          approx_times = approx_times,                                          folds = folds,                                          sample_split = TRUE,                                          SL.library = SL.library,                                          DR_pred = TRUE)  CV_full_preds <- V0_preds$CV_full_preds CV_full_preds_train <- V0_preds$CV_full_preds_train CV_S_preds <- V0_preds$CV_S_preds CV_S_preds_train <- V0_preds$CV_S_preds_train CV_G_preds <- V0_preds$CV_G_preds  # iterate over feature groups for (i in 1:length(feature_group_names)){   indx_char <- feature_groups[i]   indx_name <- feature_group_names[i]   indx <- as.numeric(strsplit(indx_char, split = \",\")[[1]])    # estimate residual oracle prediction function for this feature group   CV_reduced_preds <- CV_generate_reduced_predictions(time = time,                                               event = event,                                               X = X,                                               landmark_times = landmark_times,                                               folds = folds,                                               sample_split = sample_split,                                               indx = indx,                                               full_preds_train = CV_full_preds_train,                                               SL.library = SL.library)   # estimate VIM - note the oracle for AUC is the conditional cdf, not survival function,    # so need to take 1 - S(tau | x)   output <- vim_AUC(time = time,                     event = event,                     approx_times = approx_times,                     landmark_times = landmark_times,                     f_hat = lapply(CV_full_preds, function(x) 1-x),                     fs_hat = lapply(CV_reduced_preds, function(x) 1-x),                     S_hat = CV_S_preds,                     G_hat = CV_G_preds,                     folds = folds,                     ss_folds = ss_folds,                     sample_split = TRUE,                     scale_est = TRUE)      output$vim <- \"AUC\"   output$indx <- rep(indx_char, nrow(output))   output$indx_name <- rep(indx_name, nrow(output))   if (!(i == 1)){     pooled_output <- rbind(pooled_output, output)   } else{     pooled_output <- output   } }  # plot results p_auc <- pooled_output %>%    mutate(landmark_time = factor(landmark_time,                                 levels = c(500, 1000, 1500, 2000),                                 labels = c(\"500 days\", \"1000 days\", \"1500 days\", \"2000 days\"))) %>%   arrange(landmark_time, est) %>%   mutate(Order = row_number()) %>%   {ggplot(., aes(x = est, y = Order)) +       geom_errorbarh(aes(xmin = cil, xmax = ciu)) +       geom_point() +       theme_bw() +       xlab(\"Estimated importance\") +       ylab(\"Feature group\") +       xlim(c(0,0.3)) +       scale_y_continuous(         breaks = .$Order,         labels = .$indx_name,       ) +        facet_wrap(~landmark_time, dir = \"v\", strip.position = \"right\", scales = \"free_y\", ncol = 1) +        ggtitle(\"Subtractive AUC variable importance (doubly-robust pseudo-outcome)\")+       theme(strip.background = element_blank(),             strip.placement = \"outside\")   } p_auc"},{"path":"https://cwolock.github.io/survML/articles/variable-importance.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Assessing variable importance in survival analysis using machine learning","text":"survival variable importance methodology described Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Assessing variable importance survival analysis using machine learning.” arXiv:2311.12726. references: David R. Cox. “Regression Models Life-Tables.” Journal Royal Statistical Society: Series B (Methodological) (1972). Ted Westling, Alex Luedtke, Peter B. Gilbert Marco Carone. “Inference treatment-specific survival curves using machine learning.” Journal American Statistical Association (2023). Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). Mark J. van der Laan, Eric C. Polley Alan E. Hubbard. “Super learner”. Statistical Applications Genetics Molecular Biology (2007). Daniel Rubin Mark J. van der Laan. “doubly robust censoring unbiased transformation”. International Journal Biostatistics (2007).","code":""},{"path":"https://cwolock.github.io/survML/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Charles Wolock. Author, maintainer, copyright holder. Avi Kenny. Contributor.","code":""},{"path":"https://cwolock.github.io/survML/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wolock C (2024). survML: Tools Flexible Survival Analysis Using Machine Learning. R package version 1.1.0.9000, https://cwolock.github.io/survML/, https://github.com/cwolock/survML.","code":"@Manual{,   title = {survML: Tools for Flexible Survival Analysis Using Machine Learning},   author = {Charles Wolock},   year = {2024},   note = {R package version 1.1.0.9000, https://cwolock.github.io/survML/},   url = {https://github.com/cwolock/survML}, }"},{"path":"https://cwolock.github.io/survML/index.html","id":"survml-tools-for-flexible-survival-analysis-using-machine-learning","dir":"","previous_headings":"","what":"Tools for Flexible Survival Analysis Using Machine Learning","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"Note: current development version survML now functionality estimating variable importance, addition original survival stacking functionality included versions 1.1.0 earlier. Documentation new functionality, well new version CRAN, forthcoming. survML package contains variety functions analyzing survival data using machine learning. include: Global local survival stacking: Use --shelf machine learning tools estimate conditional survival functions. Algorithm-agnostic variable importance: Use debiased machine learning estimate make inference variable importance prediction time--event outcomes. Current-status isotonic regression: Use isotonic regression estimate covariate-adjusted survival function time--event outcome current status sampling. See package vignettes function reference details.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"installing-survml","dir":"","previous_headings":"","what":"Installing survML","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"can install stable version survML CRAN using Alternatively, development version survML available GitHub. can install using devtools package follows:","code":"install.packages(\"survML\") ## install.packages(\"devtools\") # run only if necessary install_github(repo = \"cwolock/survML\")"},{"path":"https://cwolock.github.io/survML/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"Full documentation can found survML website https://cwolock.github.io/survML/.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"bugs-reports-and-feature-requests","dir":"","previous_headings":"","what":"Bugs reports and feature requests","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"submit bug report request new feature, please submit new GitHub Issue.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"details global survival stacking, please see following paper: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “framework leveraging machine learning tools estimate personalized survival curves.” Journal Computational Graphical Statistics (2024). following preprints contain details assessing variable importance survival analysis, using isotonic regression estimate survival curves current status data, respectively: Charles J. Wolock, Peter B. Gilbert, Noah Simon Marco Carone. “Nonparametric variable importance time--event outcomes application prediction HIV infection.” arXiv:2311.12726. Charles J. Wolock, Susan Jacob, Julia C. Bennett, Anna Elias-Warren, Jessica O’Hanlon, Avi Kenny, Nicholas P. Jewell, Andrea Rotnitzky, Ana . Weil, Helen Y. Chu Marco Carone. “Investigating symptom duration using current status data: case study post-acute COVID-19 syndrome.” arXiv:2407.04214. Local survival stacking described : Eric C. Polley Mark J. van der Laan. “Super Learning Right-Censored Data” Targeted Learning (2011). Erin Craig, Chenyang Zhong, Robert Tibshirani. “Survival stacking: casting survival analysis classification problem.” arXiv:2107.13480.","code":""},{"path":"https://cwolock.github.io/survML/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Tools for Flexible Survival Analysis Using Machine Learning","text":"using survML package conditional survival estimation, please cite following: using variable importance functions, please cite following: using functionality current status data, please cite following:","code":"@article{wolock2024framework,         title={A framework for leveraging machine learning tools to estimate personalized survival curves},         author={Wolock, Charles J and Gilbert, Peter B and Simon, Noah and Carone, Marco},         journal={Journal of Computational and Graphical Statistics},         year={2024},         publisher={Taylor \\& Francis},         doi={10.1080/10618600.2024.2304070} } @article{wolock2023nonparametric,          title={Nonparametric variable importance for time-to-event outcomes with application to prediction of HIV infection},          author={Wolock, Charles J and Gilbert, Peter B and Simon, Noah and Carone, Marco},          journal={arXiv preprint arXiv:2311.12726},          year={2023} } @article{wolock2024investigating,   title={Investigating symptom duration using current status data: a case study of post-acute COVID-19 syndrome},   author={Wolock, Charles J and Jacob, Susan and Bennett, Julia C and Elias-Warren, Anna and O'Hanlon, Jessica and Kenny, Avi and Jewell, Nicholas P and Rotnitzky, Andrea and Weil, Ana A and Chu, Helen Y and Carone, Marco},   journal={arXiv preprint arXiv:2407.04214},   year={2024} }"},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a survival function under current status sampling — currstatCIR","title":"Estimate a survival function under current status sampling — currstatCIR","text":"Estimate survival function current status sampling","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a survival function under current status sampling — currstatCIR","text":"","code":"currstatCIR(   time,   event,   W,   SL_control = list(SL.library = c(\"SL.mean\"), V = 5, method = \"method.NNLS\"),   HAL_control = list(n_bins = c(5, 10), grid_type = c(\"equal_range\", \"equal_mass\"), V =     5),   deriv_method = \"m-spline\",   missing_method = \"extended\",   eval_region,   n_eval_pts = 101 )"},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a survival function under current status sampling — currstatCIR","text":"time n x 1 numeric vector observed monitoring times event n x 1 numeric vector status indicators whether event observed prior monitoring time. W Dataframe covariates SL_control List Super Learner control parameters HAL_control List haldensify control parameters deriv_method Method computing derivative missing_method Method handling nonresponse (extended CIR vs. complete case, just testing) eval_region Region estimate survival function n_eval_pts Number points grid evaluate survival function","code":""},{"path":"https://cwolock.github.io/survML/reference/currstatCIR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a survival function under current status sampling — currstatCIR","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a conditional survival function using global survival stacking — stackG","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"Estimate conditional survival function using global survival stacking","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"","code":"stackG(   time,   event = rep(1, length(time)),   entry = NULL,   X,   newX = NULL,   newtimes = NULL,   direction = \"prospective\",   time_grid_fit = NULL,   bin_size = NULL,   time_basis,   time_grid_approx = sort(unique(time)),   surv_form = \"PI\",   learner = \"SuperLearner\",   SL_control = list(SL.library = c(\"SL.mean\"), V = 10, method = \"method.NNLS\", stratifyCV     = FALSE),   tau = NULL )"},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. entry Study entry variable, applicable. Defaults NULL, indicating truncation. X n x p data.frame observed covariate values train estimator. newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. direction Whether data come prospective retrospective study. determines whether data treated subject left truncation right censoring (\"prospective\") right truncation alone (\"retrospective\"). time_grid_fit Named list numeric vectors times times discretize estimation cumulative probability functions. alternative bin_size allows specially tailored time grids rather simply using quantile bin size. list consists vectors named F_Y_1_grid, F_Y_0_grid, G_W_1_grid, G_W_0_grid. denote, respectively, grids used estimate conditional CDF time variable among uncensored censored observations, grids used estimate conditional distribution entry variable among uncensored censored observations. bin_size Size time bin discretize estimation cumulative probability functions. Can number 0 1, indicating size quantile grid (e.g. 0.1 estimates cumulative probability functions grid based deciles observed times). NULL, creates grid observed times. time_basis treat time training binary classifier. Options \"continuous\" \"dummy\", meaning indicator variable included time time grid. time_grid_approx Numeric vector times approximate product integral cumulative hazard interval. Defaults times argument. surv_form Mapping hazard estimate survival estimate. Can either \"PI\" (product integral mapping) \"exp\" (exponentiated cumulative hazard estimate). learner binary regression algorithm use. Currently, SuperLearner supported, learners added. See algorithm-specific arguments. SL_control Named list parameters controlling Super Learner fitting process. parameters passed directly SuperLearner function. Parameters include SL.library (library algorithms include binary classification Super Learner), V (Number cross validation folds train Super Learner classifier, defaults 10), method (Method estimating coefficients Super Learner, defaults \"method.NNLS\"), stratifyCV (logical indicating whether stratify outcome SuperLearner's cross-validation scheme), obsWeights (observation weights, passed directly prediction algorithms SuperLearner). tau maximum time interest study, used retrospective conditional survival estimation. Rather dealing right truncation separately left truncation, simpler estimate survival function tau - time. Defaults NULL, case maximum study entry time chosen reference point.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"named list class stackG, following components: S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. S_C_preds m x k matrix estimated censoring time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. time_grid_approx approximation grid product integral cumulative hazard integral, (user-specified). direction Whether data come prospective retrospective study (user-specified). tau maximum time interest study, used retrospective conditional survival estimation (user-specified). surv_form Exponential product-integral form (user-specified). time_basis Whether time included regression continuous dummy (user-specified). SL_control Named list parameters controlling Super Learner fitting process (user-specified). fits named list fitted regression objects corresponding constituent regressions needed global survival stacking. Includes P_Delta (probability event given covariates), F_Y_1 (conditional cdf follow-times given covariates among uncensored), F_Y_0 (conditional cdf follow-times given covariates among censored), G_W_1 (conditional distribution entry times given covariates follow-time among uncensored), G_W_0 (conditional distribution entry times given covariates follow-time among uncensored). objects includes estimated coefficients SuperLearner fit, well time grid used create stacked dataset (applicable).","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"Wolock C.J., Gilbert P.B., Simon N., Carone, M. (2022). \"framework leveraging machine learning tools estimate personalized survival curves.\"","code":""},{"path":"https://cwolock.github.io/survML/reference/stackG.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate a conditional survival function using global survival stacking — stackG","text":"","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackG(time = time,               event = event,               entry = entry,               X = X,               newX = X,               newtimes = seq(0, 15, .1),               direction = \"prospective\",               bin_size = 0.1,               time_basis = \"continuous\",               time_grid_approx = sort(unique(time)),               surv_form = \"exp\",               learner = \"SuperLearner\",               SL_control = list(SL.library = SL.library,                                 V = 5))  plot(fit$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate a conditional survival function via local survival stacking — stackL","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"Estimate conditional survival function via local survival stacking","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"","code":"stackL(   time,   event = rep(1, length(time)),   entry = NULL,   X,   newX,   newtimes,   direction = \"prospective\",   bin_size = NULL,   time_basis = \"continuous\",   learner = \"SuperLearner\",   SL_control = list(SL.library = c(\"SL.mean\"), V = 10, method = \"method.NNLS\", stratifyCV     = FALSE),   tau = NULL )"},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. entry Study entry variable, applicable. Defaults NULL, indicating truncation. X n x p data.frame observed covariate values train estimator. newX m x p data.frame new observed covariate values obtain m predictions estimated algorithm. Must names structure X. newtimes k x 1 numeric vector times obtain k predicted conditional survivals. direction Whether data come prospective retrospective study. determines whether data treated subject left truncation right censoring (\"prospective\") right truncation alone (\"retrospective\"). bin_size Size bins discretization time. value 0 1 indicating size observed event time quantiles grid times (e.g. 0.02 creates grid 50 times evenly spaced quantile scaled). NULL, defaults every observed event time. time_basis treat time training binary classifier. Options \"continuous\" \"dummy\", meaning indicator variable included time time grid. learner binary regression algorithm use. Currently, SuperLearner supported, learners added. See algorithm-specific arguments. SL_control Named list parameters controlling Super Learner fitting process. parameters passed directly SuperLearner function. Parameters include SL.library (library algorithms include binary classification Super Learner), V (Number cross validation folds train Super Learner classifier, defaults 10), method (Method estimating coefficients Super Learner, defaults \"method.NNLS\"), stratifyCV (logical indicating whether stratify outcome SuperLearner's cross-validation scheme), obsWeights (observation weights, passed directly prediction algorithms SuperLearner). tau maximum time interest study, used retrospective conditional survival estimation. Rather dealing right truncation separately left truncation, simpler estimate survival function tau - time. Defaults NULL, case maximum study entry time chosen reference point.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"named list class stackL. S_T_preds m x k matrix estimated event time survival probabilities m covariate vector values k times provided user newX newtimes, respectively. fit Super Learner fit binary classification stacked dataset.","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"Polley E.C. van der Laan M.J. (2011). \"Super Learning Right-Censored Data\" Targeted Learning. Craig E., Zhong C., Tibshirani R. (2021). \"Survival stacking: casting survival analysis classification problem.\"","code":""},{"path":"https://cwolock.github.io/survML/reference/stackL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate a conditional survival function via local survival stacking — stackL","text":"","code":"# This is a small simulation example set.seed(123) n <- 500 X <- data.frame(X1 = rnorm(n), X2 = rbinom(n, size = 1, prob = 0.5))  S0 <- function(t, x){   pexp(t, rate = exp(-2 + x[,1] - x[,2] + .5 * x[,1] * x[,2]), lower.tail = FALSE) } T <- rexp(n, rate = exp(-2 + X[,1] - X[,2] + .5 *  X[,1] * X[,2]))  G0 <- function(t, x) {   as.numeric(t < 15) *.9*pexp(t,                               rate = exp(-2 -.5*x[,1]-.25*x[,2]+.5*x[,1]*x[,2]),                               lower.tail=FALSE) } C <- rexp(n, exp(-2 -.5 * X[,1] - .25 * X[,2] + .5 * X[,1] * X[,2])) C[C > 15] <- 15  entry <- runif(n, 0, 15)  time <- pmin(T, C) event <- as.numeric(T <= C)  sampled <- which(time >= entry) X <- X[sampled,] time <- time[sampled] event <- event[sampled] entry <- entry[sampled]  # Note that this a very small Super Learner library, for computational purposes. SL.library <- c(\"SL.mean\", \"SL.glm\")  fit <- stackL(time = time,                event = event,                entry = entry,                X = X,                newX = X,                newtimes = seq(0, 15, .1),                direction = \"prospective\",                bin_size = 0.1,                time_basis = \"continuous\",                SL_control = list(SL.library = SL.library,                                  V = 5))  plot(fit$S_T_preds[1,], S0(t =  seq(0, 15, .1), X[1,])) abline(0,1,col='red')"},{"path":"https://cwolock.github.io/survML/reference/survML-package.html","id":null,"dir":"Reference","previous_headings":"","what":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","title":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","text":"Statistical tools analyzing time--event data using machine learning. Implements survival stacking conditional survival estimation, isotonic regression current status data, methods algorithm-agnostic variable importance. See Wolock CJ, Gilbert PB, Simon N, Carone M (2024) doi:10.1080/10618600.2024.2304070 .","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/reference/survML-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"survML: Tools for Flexible Survival Analysis Using Machine Learning — survML-package","text":"Maintainer: Charles Wolock cwolock@gmail.com (ORCID) [copyright holder] contributors: Avi Kenny avi.kenny@gmail.com (ORCID) [contributor]","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate AUC VIM — vim_AUC","title":"Estimate AUC VIM — vim_AUC","text":"Estimate AUC VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate AUC VIM — vim_AUC","text":"","code":"vim_AUC(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   sample_split,   ss_folds,   robust = TRUE,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate AUC VIM — vim_AUC","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate AUC f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds robust Logical, whether use doubly-robust debiasing approach. option meant illustration purposes — left TRUE. scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_AUC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate AUC VIM — vim_AUC","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate classification accuracy VIM — vim_accuracy","title":"Estimate classification accuracy VIM — vim_accuracy","text":"Estimate classification accuracy VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate classification accuracy VIM — vim_accuracy","text":"","code":"vim_accuracy(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate classification accuracy VIM — vim_accuracy","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate accuracy f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate classification accuracy VIM — vim_accuracy","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Brier score VIM — vim_brier","title":"Estimate Brier score VIM — vim_brier","text":"Estimate Brier score VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Brier score VIM — vim_brier","text":"","code":"vim_brier(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   ss_folds,   sample_split,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Brier score VIM — vim_brier","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate Brier score f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds ss_folds Numeric vector length n giving sample-splitting folds sample_split Logical indicating whether sample split scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_brier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Brier score VIM — vim_brier","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate concordance index VIM — vim_cindex","title":"Estimate concordance index VIM — vim_cindex","text":"Estimate concordance index VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate concordance index VIM — vim_cindex","text":"","code":"vim_cindex(   time,   event,   approx_times,   tau,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate concordance index VIM — vim_cindex","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. tau restriction time f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_cindex.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate concordance index VIM — vim_cindex","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rmst_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate restricted prediction time MSE VIM — vim_rmst_mse","title":"Estimate restricted prediction time MSE VIM — vim_rmst_mse","text":"Estimate restricted prediction time MSE VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rmst_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate restricted prediction time MSE VIM — vim_rmst_mse","text":"","code":"vim_rmst_mse(   time,   event,   approx_times,   tau,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   sample_split,   ss_folds,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_rmst_mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate restricted prediction time MSE VIM — vim_rmst_mse","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. tau restriction time f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds sample_split Logical indicating whether sample split ss_folds Numeric vector length n giving sample-splitting folds scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rmst_mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate restricted prediction time MSE VIM — vim_rmst_mse","text":"data frame giving results","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Brier score VIM — vim_rsquared","title":"Estimate Brier score VIM — vim_rsquared","text":"Estimate Brier score VIM","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Brier score VIM — vim_rsquared","text":"","code":"vim_rsquared(   time,   event,   approx_times,   landmark_times,   f_hat,   fs_hat,   S_hat,   G_hat,   folds,   ss_folds,   sample_split,   scale_est = FALSE,   alpha = 0.05 )"},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Brier score VIM — vim_rsquared","text":"time n x 1 numeric vector observed follow-times censoring, minimum event censoring times. event n x 1 numeric vector status indicators whether event observed. Defaults vector 1s, .e. censoring. approx_times Numeric vector length J1 giving times approximate integrals. landmark_times Numeric vector length J2 giving times estimate Brier score f_hat Full oracle predictions (n x J1 matrix) fs_hat Residual oracle predictions (n x J1 matrix) S_hat Estimates conditional event time survival function (n x J2 matrix) G_hat Estimate conditional censoring time survival function (n x J2 matrix) folds Numeric vector length n giving cross-fitting folds ss_folds Numeric vector length n giving sample-splitting folds sample_split Logical indicating whether sample split scale_est Logical, whether force VIM estimate nonnegative alpha level compute confidence intervals hypothesis tests. Defaults 0.05","code":""},{"path":"https://cwolock.github.io/survML/reference/vim_rsquared.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Brier score VIM — vim_rsquared","text":"data frame giving results","code":""},{"path":[]},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-110","dir":"Changelog","previous_headings":"","what":"survML 1.1.0","title":"survML 1.1.0","text":"CRAN release: 2024-03-17 Added gam SUGGESTS order allow SuperLearner package make corresponding change without breaking vignettes. Added time_grid_fit option main stackG function order allow flexibility choosing time grids. Minor bug fixes.","code":""},{"path":"https://cwolock.github.io/survML/news/index.html","id":"survml-100","dir":"Changelog","previous_headings":"","what":"survML 1.0.0","title":"survML 1.0.0","text":"CRAN release: 2023-07-08 Initial CRAN submission.","code":""}]
